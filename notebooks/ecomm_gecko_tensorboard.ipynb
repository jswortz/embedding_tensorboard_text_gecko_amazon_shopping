{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting batch prediction EDA with Tensor Board and Text Gecko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, List\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "LIMIT = 3000\n",
    "PROJECT_ID = 'wortz-project-352116'\n",
    "DATASET = 'ecomm-embedding'\n",
    "BUCKET = 'gs://ecomm-query-product-pairs'\n",
    "USER_PROMPT = 'User query: '\n",
    "PRODUCT_PROMPT = 'Product title: '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_dataset(\"tasksource/esci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick examination of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_jsonl_from_raw_data(jsonl_path: str, id_field: str, text_field: str, raw_data = raw_data) -> None:\n",
    "    if 'product_id' in id_field:\n",
    "        initial_list = raw_data['train'].map(lambda example: {'_id': {example[id_field]}, 'title': example['product_title'], 'text': example[text_field]})\n",
    "    else:\n",
    "        initial_list = raw_data['train'].map(lambda example: {'_id': {example[id_field]}, 'text': example[text_field]})\n",
    "    _ , unique_indices = np.unique(initial_list, return_index=True, axis=0)\n",
    "    filtered_dataset = dataset.select(unique_indices.tolist())\n",
    "    filtered_dataset.to_json(jsonl_path)\n",
    "    \n",
    "def create_jsonl_training_labels(tsv_train_path: str, tsv_path_test: str, raw_data = raw_data) -> None:\n",
    "    tsv_options = {'sep': '\\t'}\n",
    "    train_data = raw_data['train'].map(lambda example: {'query-id': example['query_id'], 'corpus-id': example['product_id']})\n",
    "    test_data = raw_data['test'].map(lambda example: {'query-id': example['query_id'], 'corpus-id': example['product_id']})\n",
    "    train_data.to_csv(tsv_train_path, **tsv_options)\n",
    "    test_data.to_csv(tsv_test_path, **tsv_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2027874/2027874 [06:19<00:00, 5350.45 examples/s]\n",
      "Map: 100%|██████████| 652490/652490 [02:02<00:00, 5318.53 examples/s]\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 0 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtuning_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#the corpus file https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-embeddings#prepare-tuning\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcreate_jsonl_from_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjsonl_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtuning_data/query.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# the query file\u001b[39;00m\n\u001b[1;32m      8\u001b[0m create_jsonl_from_raw_data(jsonl_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtuning_data/corpus.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, id_field\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m, text_field\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_description\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[117], line 6\u001b[0m, in \u001b[0;36mcreate_jsonl_from_raw_data\u001b[0;34m(jsonl_path, id_field, text_field, raw_data)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     initial_list \u001b[38;5;241m=\u001b[39m raw_data\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m example: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m'\u001b[39m: {example[id_field]}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: example[text_field]})\n\u001b[0;32m----> 6\u001b[0m _ , unique_indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m filtered_dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mselect(unique_indices\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m      8\u001b[0m filtered_dataset\u001b[38;5;241m.\u001b[39mto_json(jsonl_path)\n",
      "File \u001b[0;32m/opt/conda/envs/tensorboard-four/lib/python3.12/site-packages/numpy/lib/arraysetops.py:283\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    280\u001b[0m     ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(ar, axis, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m np\u001b[38;5;241m.\u001b[39mAxisError:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# this removes the \"axis1\" or \"axis2\" prefix from the error message\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m np\u001b[38;5;241m.\u001b[39mAxisError(axis, ar\u001b[38;5;241m.\u001b[39mndim) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# Must reshape to a contiguous 2D array for this to work...\u001b[39;00m\n\u001b[1;32m    286\u001b[0m orig_shape, orig_dtype \u001b[38;5;241m=\u001b[39m ar\u001b[38;5;241m.\u001b[39mshape, ar\u001b[38;5;241m.\u001b[39mdtype\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 0 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('tuning_data/'):\n",
    "    os.mkdir('tuning_data/')\n",
    "    \n",
    "#the corpus file https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-embeddings#prepare-tuning\n",
    "create_jsonl_from_raw_data(jsonl_path='tuning_data/query.jsonl', id_field='query_id', text_field='query')\n",
    "\n",
    "# the query file\n",
    "create_jsonl_from_raw_data(jsonl_path='tuning_data/corpus.jsonl', id_field='product_id', text_field='product_description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lastly, get training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_fine_tuning_dataframe(raw_data: datasets.dataset_dict.DatasetDict, unique_queries: Dict, unique_products: Dict, split: str = 'train') -> Tuple[pd.Dataframe, pd.Dataframe]:\n",
    "#     ### https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-embeddings#generative-ai-tune-embedding-drest\n",
    "#     data_dict_corpus = {\"_id\": [], \"text\": []}\n",
    "#     data_dict_query = data_dict_corpus.copy()\n",
    "#     raw_data = raw_data[split]\n",
    "#     for row in raw_data:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dataframe(\n",
    "    raw_data: Dict,\n",
    "    user_prompt: str = USER_PROMPT,\n",
    "    product_prompt: str = PRODUCT_PROMPT,\n",
    "    limit: int = LIMIT,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function returns batch prediction data for embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    for i, row in enumerate(raw_data[\"train\"]):\n",
    "        if i == limit - 1:\n",
    "            break\n",
    "        elif i == 0:\n",
    "            query_prod_pairs = pd.DataFrame(\n",
    "                {\"content\": [f'{user_prompt}{row[\"query\"]}'], \"type\": [\"query\"], \"id\": [row[\"query_id\"]]}\n",
    "            )\n",
    "        else:\n",
    "            query_prod_pairs = pd.concat(\n",
    "                [\n",
    "                    query_prod_pairs,\n",
    "                    pd.DataFrame(\n",
    "                        {\"content\": [f'{user_prompt}{row[\"query\"]}'], \"type\": [\"query\"], \"id\": [row[\"query_id\"]]}\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        query_prod_pairs = pd.concat(\n",
    "            [\n",
    "                query_prod_pairs,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"content\": [f'{product_prompt}{row[\"product_title\"]}'],\n",
    "                        \"type\": [\"product_title\"], \"id\": [row[\"product_id\"]]}\n",
    "                    \n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    return query_prod_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod_pairs = get_input_dataframe(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>User query:  revent 80 cfm</td>\n",
       "      <td>query</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Product title: Panasonic FV-20VQ3 WhisperCeili...</td>\n",
       "      <td>product_title</td>\n",
       "      <td>B000MOO21W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>User query: bathroom fan without light</td>\n",
       "      <td>query</td>\n",
       "      <td>13723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Product title: Panasonic FV-20VQ3 WhisperCeili...</td>\n",
       "      <td>product_title</td>\n",
       "      <td>B000MOO21W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>User query:  revent 80 cfm</td>\n",
       "      <td>query</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            content           type  \\\n",
       "0      0                         User query:  revent 80 cfm          query   \n",
       "1      0  Product title: Panasonic FV-20VQ3 WhisperCeili...  product_title   \n",
       "2      0             User query: bathroom fan without light          query   \n",
       "3      0  Product title: Panasonic FV-20VQ3 WhisperCeili...  product_title   \n",
       "4      0                         User query:  revent 80 cfm          query   \n",
       "\n",
       "           id  \n",
       "0           0  \n",
       "1  B000MOO21W  \n",
       "2       13723  \n",
       "3  B000MOO21W  \n",
       "4           0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_prod_pairs = query_prod_pairs.reset_index()\n",
    "query_prod_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get unique product ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch prediction\n",
    "\n",
    "https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/batch-prediction-genai-embeddings#request_a_batch_response\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil mb $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'batch_prediction_inputs.jsonl'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(query_prod_pairs[['content']].to_json(lines=True, orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp $output_file $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "now_string_tag = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(\"Tag for this run: \", now_string_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "textembedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko\")\n",
    "batch_prediction_job = textembedding_model.batch_predict(\n",
    "    dataset=[f\"{BUCKET}/{output_file}\"],\n",
    "    destination_uri_prefix=f\"{BUCKET}/batch-predict-{now_string_tag}\",\n",
    ")\n",
    "print(batch_prediction_job.display_name)\n",
    "print(batch_prediction_job.resource_name)\n",
    "print(batch_prediction_job.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When complete you should see something like this\n",
    "\n",
    "<img src='../img/bp-job.png' width=600px />\n",
    "\n",
    "<img src='../img/output-data.png' width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the embeddings with Tensorboard\n",
    "\n",
    "Following this guide https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_output_gcs_folder = batch_prediction_job.output_info.gcs_output_directory\n",
    "\n",
    "! gsutil cp $bp_output_gcs_folder/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_json(path_or_buf='000000000000.jsonl', lines=True)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df: pd.DataFrame) -> List[List[float]]:\n",
    "    embedding_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        single_emb = row['predictions'][0]['embeddings']['values']\n",
    "        embedding_list.append(single_emb)\n",
    "    return embedding_list\n",
    "\n",
    "embedding_list = get_predictions(predictions)\n",
    "len(embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files.\n",
    "log_dir = \"logs/ecomm-example/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, \"metadata.tsv\"), \"w\") as f:\n",
    "    #header for columns\n",
    "    f.write(\"data_type\\tdata\\n\")\n",
    "    for instance in predictions.instance:\n",
    "        data_type = instance['content'].split(': ')[0]\n",
    "        # data_type = data_type\n",
    "        data = ''.join(instance['content'].split(': ')[1:])\n",
    "        f.write(f\"{data_type}\\t{data}\\n\")\n",
    "\n",
    "\n",
    "# Save the weights we want to analyze as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, here\n",
    "# we will remove this value.\n",
    "weights = tf.Variable(embedding_list)\n",
    "# Create a checkpoint from embedding, the filename and key are the\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = \"metadata.tsv\"\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 30352), started 0:08:44 ago. (Use '!kill 30352' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-eb0817d48ad4c9b8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-eb0817d48ad4c9b8\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now run tensorboard against on log data we just saved.\n",
    "%tensorboard --logdir logs/ecomm-example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above will run until you stop it\n",
    "\n",
    "You should be able to investigate the embedding space via PCA. Note the total variance captured to understand how complete the veiw investigate\n",
    "\n",
    "<img src=\"../img/tensorboard.png\" width=600px />\n",
    "\n",
    "\n",
    "#### Also a great way to understand performance is to select a point of interest and top k neighbors appear\n",
    "\n",
    "Below, we see natural hair dye query and it's associated nearest product description in the embedding space:\n",
    "\n",
    "\n",
    "<img src=\"../img/knn-analysis.png\" width=900px />\n",
    "\n",
    "\n",
    "#### Lastly, you can analyze and color by data type to get a feel for how well the queryies releate to the products\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../img/analysis-by-type.png\" width=900px />\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorboard-four-tensorboard-four",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "tensorboard-four (Local)",
   "language": "python",
   "name": "conda-env-tensorboard-four-tensorboard-four"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

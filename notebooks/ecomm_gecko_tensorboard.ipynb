{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting batch prediction EDA with Tensor Board and Text Gecko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, List\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "LIMIT = 3000\n",
    "PROJECT_ID = \"wortz-project-352116\"\n",
    "DATASET = \"ecomm-embedding\"\n",
    "BUCKET_NAME = \"ecomm-query-product-pairs\"\n",
    "BUCKET = f\"gs://{BUCKET_NAME}\"\n",
    "USER_PROMPT = \"User query: \"\n",
    "PRODUCT_PROMPT = \"Product title: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_dataset(\"tasksource/esci\")  # , split=['train[:10%]','test[:10%]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick examination of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Total features: \", len(raw_data.column_names[\"train\"]))\n",
    "all_features = raw_data.column_names[\"train\"]\n",
    "all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guide for embedding fine tuning\n",
    "\n",
    "https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data = load_dataset(\"tasksource/esci\", split=[\"train[:10%]\", \"test[:10%]\"])\n",
    "train_split = raw_data[0]\n",
    "test_split = raw_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_jsonl_from_raw_data(\n",
    "    query_path: str,\n",
    "    corpus_path: str,\n",
    "    training_path: str,\n",
    "    test_path: str,\n",
    "    train_split=train_split,\n",
    "    test_split=test_split,\n",
    "    all_features=all_features,\n",
    "    **kwargs,\n",
    ") -> None:\n",
    "\n",
    "    pandas_data_train = train_split.map(\n",
    "        lambda example: {\n",
    "          \"query\": f\"{example[\"query\"]}\",\n",
    "            \"product_text\": f\"{example[\"product_text\"]}\",\n",
    "            \"query-id\": str(example[\"query_id\"]),\n",
    "            \"corpus-id\": str(example[\"product_id\"]),\n",
    "            \"score\": 1,\n",
    "        },\n",
    "        remove_columns=all_features,\n",
    "    ).to_pandas()\n",
    "\n",
    "    pandas_data_test = train_split.map(\n",
    "        lambda example: {\n",
    "            \"query\": f\"{example[\"query\"]}\",\n",
    "            \"product_text\": f\"{example[\"product_text\"]}\",\n",
    "            \"query-id\": str(example[\"query_id\"]),\n",
    "            \"corpus-id\": str(example[\"product_id\"]),\n",
    "            \"score\": 1,\n",
    "        },\n",
    "        remove_columns=all_features,\n",
    "    ).to_pandas()\n",
    "\n",
    "    \n",
    "    ### Data processing to create unique query and corpus vocab for training\n",
    "    ### Plus examples\n",
    "    rename_corpus = {\"corpus-id\": \"_id\", \"product_text\": \"text\"}\n",
    "    rename_queries = {\"query-id\": \"_id\", \"query\": \"text\"}\n",
    "    unique_corpus = pandas_data_train[[\"corpus-id\", \"product_text\"]].rename(columns=rename_corpus)\n",
    "    unique_corpus = unique_corpus.drop_duplicates(subset=\"_id\")\n",
    "    unique_queries = pandas_data_train[[\"query-id\", \"query\"]].rename(columns=rename_queries)\n",
    "    unique_queries.drop_duplicates(subset=\"_id\")\n",
    "    full_dataset_train = pandas_data_train[['query-id', 'corpus-id', 'score']]\n",
    "    full_dataset_test = pandas_data_test[['query-id', 'corpus-id', 'score']]\n",
    "\n",
    "    with open(query_path, \"w\") as f:\n",
    "        f.write(unique_queries.to_json(lines=True, orient=\"records\"))\n",
    "    with open(corpus_path, \"w\") as f:\n",
    "        f.write(unique_corpus.to_json(lines=True, orient=\"records\"))\n",
    "    full_dataset_train.to_csv(training_path, sep=\"\\t\")\n",
    "    full_dataset_test.to_csv(test_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### For large file ops we will use gcs fuse to save directly to the bucket\n",
    "\n",
    "`gcsfuse $BUCKET $data_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"time\":\"23/03/2024 10:37:47.705614\",\"severity\":\"INFO\",\"message\":\"Start gcsfuse/2.0.0 (Go version go1.22.1) for app \\\"\\\" using mount point: /home/user/embedding_tensorboard_text_gecko_amazon_shopping/notebooks/tuning_data\\n\"}\n",
      "{\"time\":\"23/03/2024 10:37:47.706134\",\"severity\":\"INFO\",\"message\":\"GCSFuse mount command flags: {\\\"AppName\\\":\\\"\\\",\\\"Foreground\\\":false,\\\"ConfigFile\\\":\\\"\\\",\\\"MountOptions\\\":{},\\\"DirMode\\\":493,\\\"FileMode\\\":420,\\\"Uid\\\":-1,\\\"Gid\\\":-1,\\\"ImplicitDirs\\\":false,\\\"OnlyDir\\\":\\\"\\\",\\\"RenameDirLimit\\\":0,\\\"CustomEndpoint\\\":null,\\\"BillingProject\\\":\\\"\\\",\\\"KeyFile\\\":\\\"\\\",\\\"TokenUrl\\\":\\\"\\\",\\\"ReuseTokenFromUrl\\\":true,\\\"EgressBandwidthLimitBytesPerSecond\\\":-1,\\\"OpRateLimitHz\\\":-1,\\\"SequentialReadSizeMb\\\":200,\\\"MaxRetrySleep\\\":30000000000,\\\"StatCacheCapacity\\\":20460,\\\"StatCacheTTL\\\":60000000000,\\\"TypeCacheTTL\\\":60000000000,\\\"HttpClientTimeout\\\":0,\\\"MaxRetryDuration\\\":-1000000000,\\\"RetryMultiplier\\\":2,\\\"LocalFileCache\\\":false,\\\"TempDir\\\":\\\"\\\",\\\"ClientProtocol\\\":\\\"http1\\\",\\\"MaxConnsPerHost\\\":100,\\\"MaxIdleConnsPerHost\\\":100,\\\"EnableNonexistentTypeCache\\\":false,\\\"StackdriverExportInterval\\\":0,\\\"OtelCollectorAddress\\\":\\\"\\\",\\\"LogFile\\\":\\\"\\\",\\\"LogFormat\\\":\\\"json\\\",\\\"ExperimentalEnableJsonRead\\\":false,\\\"DebugFuseErrors\\\":true,\\\"DebugFuse\\\":false,\\\"DebugFS\\\":false,\\\"DebugGCS\\\":false,\\\"DebugHTTP\\\":false,\\\"DebugInvariants\\\":false,\\\"DebugMutex\\\":false}\"}\n",
      "{\"time\":\"23/03/2024 10:37:47.706275\",\"severity\":\"INFO\",\"message\":\"GCSFuse mount config flags: {\\\"CreateEmptyFile\\\":false,\\\"Severity\\\":\\\"INFO\\\",\\\"Format\\\":\\\"json\\\",\\\"FilePath\\\":\\\"\\\",\\\"LogRotateConfig\\\":{\\\"MaxFileSizeMB\\\":512,\\\"BackupFileCount\\\":10,\\\"Compress\\\":true},\\\"MaxSizeMB\\\":-1,\\\"CacheFileForRangeRead\\\":false,\\\"CacheDir\\\":\\\"\\\",\\\"TtlInSeconds\\\":-9223372036854775808,\\\"TypeCacheMaxSizeMB\\\":4,\\\"StatCacheMaxSizeMB\\\":-9223372036854775808,\\\"EnableEmptyManagedFolders\\\":false}\"}\n",
      "daemonize.Run: readFromProcess: sub-process: Error while mounting gcsfuse: mountWithArgs: mountWithStorageHandle: Mount: mount: running /usr/bin/fusermount: exit status 1\n"
     ]
    }
   ],
   "source": [
    "#establish mount point\n",
    "data_path = 'tuning_data'\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)\n",
    "!gcsfuse $BUCKET_NAME $data_path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create gcs subfolder - why? this ensures we are not in the root for this and keeping the artifacts organized\n",
    "if not os.path.exists(os.path.join(data_path, data_path)):\n",
    "    os.mkdir(os.path.join(data_path, data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function processes the data and puts it into the proper paths\n",
    "Data is stored in gcs via GCSFuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the corpus file https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-embeddings#prepare-tuning\n",
    "create_jsonl_from_raw_data(\n",
    "        query_path = f\"{data_path}/{data_path}/query.jsonl\",\n",
    "    corpus_path= f\"{data_path}//{data_path}/corpus.jsonl\",\n",
    "    training_path= f\"{data_path}/{data_path}/corpus-train.TSV\",\n",
    "    test_path= f\"{data_path}/{data_path}/corpus-test.TSV\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set tuning parameters in cell below\n",
    "\n",
    "Many of these are copy/paste from settings in first cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"projects/679926387543/locations/us-central1/pipelineJobs/tune-text-embedding-20240323223758\",\n",
      "  \"displayName\": \"tune-text-embedding-model\",\n",
      "  \"createTime\": \"2024-03-23T22:37:58.266808Z\",\n",
      "  \"updateTime\": \"2024-03-23T22:37:58.266808Z\",\n",
      "  \"pipelineSpec\": {\n",
      "    \"deploymentConfig\": {\n",
      "      \"@type\": \"type.googleapis.com/ml_pipelines.PipelineDeploymentConfig\",\n",
      "      \"executors\": {\n",
      "        \"exec-text-embedding-autosplitter\": {\n",
      "          \"container\": {\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.3.1\",\n",
      "            \"command\": [\n",
      "              \"sh\",\n",
      "              \"-ec\",\n",
      "              \"program_path=$(mktemp -d)\\n\\nprintf \\\"%s\\\" \\\"$0\\\" \\u003e \\\"$program_path/ephemeral_component.py\\\"\\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \\\"$program_path/ephemeral_component.py\\\"                         \\\"$@\\\"\\n\",\n",
      "              \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import *\\n\\ndef text_embedding_autosplitter(\\n    base_model_version_id: str,\\n    allowed_model_ids: List[str],\\n    query_jsonl_path: str,\\n    corpus_jsonl_path: str,\\n    train_label_path: str,\\n    autosplitting_output: dsl.Output[dsl.Dataset],\\n    task_type: str = 'DEFAULT',\\n    test_label_path: str = '',\\n    validation_label_path: str = '',\\n    test_autosplit_ratio: float = 0.2,\\n    validation_autosplit_ratio: float = 0.2,\\n) -\\u003e NamedTuple(\\n    'ValidationOutput',\\n    [\\n        ('model_upload_labels', Dict[str, str]),\\n        ('train_tsv', str),\\n        ('test_tsv', str),\\n        ('validation_tsv', str),\\n        ('llm_model_template_name', str),\\n    ],\\n):\\n  \\\"\\\"\\\"Validates pipeline parameters, and autosplits test and validation data.\\n\\n  Args:\\n    base_model_version_id: The full public version ID of the embedding model to\\n      tune.\\n    allowed_model_ids: The list of valid version IDs. This parameter is provided\\n      by the pipeline definition.\\n    query_jsonl_path: The path to queries in JSONL format.\\n    corpus_jsonl_path: The path to the corpus in JSONL format.\\n    train_label_path: The path to training labels in TSV format.\\n    autosplitting_output: The directory to output the autosplit dataset.\\n      Autogenerated by Kubeflow.\\n    task_type: Which task to optimize the model for.\\n    test_label_path: Path to test labels in TSV format.\\n    validation_label_path: Path to validation labels in TSV format.\\n    test_autosplit_ratio: The percentage to split out for the test dataset, if\\n      `test_label_path` is not provided.\\n    validation_autosplit_ratio: The percentage to split out for the validation\\n      dataset, if `validation_label_path` is not provided.\\n\\n  Returns:\\n    A `NamedTuple` with the following properties:\\n      - `model_upload_labels`: A dictionary of labels, to be added to the Vertex\\n      Model.\\n      - `train_tsv`: Path to the train labels.\\n      - `test_tsv`: Path to the test labels.\\n      - `validation_tsv`: Path to the validation labels.\\n      - `llm_model_template_name`: The name of the model template to use for\\n      tuning.\\n\\n  Raises:\\n    A `ValueError` if the parameters or data cannot be read or are invalid. All\\n    internal exceptions trigger a `SystemExit` with code `13`.\\n  \\\"\\\"\\\"\\n  import collections\\n  import logging\\n  import math\\n  import os\\n  import pandas as pd\\n  import sys\\n  import typing\\n\\n  _MIN_LABELS_SIZE = 3\\n  _MIN_QUERY = 1\\n  _MIN_CORPUS = 1\\n  _MAX_QUERY = 40_000\\n  _MAX_CORPUS = 500_000\\n\\n  _QUERY_COL = 'query-id'\\n  _CORPUS_COL = 'corpus-id'\\n  _SCORE_COL = 'score'\\n\\n  _GCS_FUSE_PREFIX = '/gcs/'\\n  _GCS_PREFIX = 'gs://'\\n  _ALL_TASK_TYPES = (\\n      'DEFAULT',\\n      'RETRIEVAL_DOCUMENT',\\n      'RETRIEVAL_QUERY',\\n      'SEMANTIC_SIMILARITY',\\n      'CLUSTERING',\\n      'CLASSIFICATION',\\n  )\\n  _GECKO_001_MODEL_ID = 'textembedding-gecko@001'\\n\\n  class UserError(ValueError):\\n    \\\"\\\"\\\"Error signaling an issue with the supplied parameters or data.\\\"\\\"\\\"\\n\\n  def _to_gcs_fuse(path: Optional[str]) -\\u003e Optional[str]:\\n    \\\"\\\"\\\"Converts gs:// paths to /gcs/.\\\"\\\"\\\"\\n    return (\\n        path.replace(_GCS_PREFIX, _GCS_FUSE_PREFIX, 1)\\n        if path and path.startswith(_GCS_PREFIX)\\n        else path\\n    )\\n\\n  def _to_gs_doubleslash(path: str) -\\u003e str:\\n    \\\"\\\"\\\"Converts /gcs/ paths to gs://.\\\"\\\"\\\"\\n    return (\\n        path.replace(_GCS_FUSE_PREFIX, _GCS_PREFIX, 1)\\n        if path.startswith(_GCS_FUSE_PREFIX)\\n        else path\\n    )\\n\\n  # These paths will only be written to if the datasets do not already exist.\\n  _OUT_DIR = _to_gcs_fuse(autosplitting_output.uri)\\n  _TRAIN_OUT = os.path.join(_OUT_DIR, 'train_labels.tsv')\\n  _VALIDATION_OUT = os.path.join(_OUT_DIR, 'validation_labels.tsv')\\n  _TEST_OUT = os.path.join(_OUT_DIR, 'test_labels.tsv')\\n  os.makedirs(_OUT_DIR, exist_ok=True)\\n\\n  ValidationOutput = collections.namedtuple(\\n      'ValidationOutput',\\n      [\\n          'model_upload_labels',\\n          'train_tsv',\\n          'test_tsv',\\n          'validation_tsv',\\n          'llm_model_template_name',\\n      ],\\n  )\\n\\n  def raise_user_error_on_failure(fn):\\n    \\\"\\\"\\\"Wraps a function, reraising any thrown exception as a `UserError`.\\\"\\\"\\\"\\n\\n    def _inner(*args, **kwargs):\\n      try:\\n        return fn(*args, **kwargs)\\n      except Exception as e:  # pylint: disable=broad-exception-caught\\n        raise UserError(str(e)) from e\\n\\n    return _inner\\n\\n  @raise_user_error_on_failure\\n  def _read_label_tsv(input_path: str) -\\u003e pd.DataFrame:\\n    \\\"\\\"\\\"Reads label data (`query-id`, `corpus-id`, `score`) from TSV file.\\\"\\\"\\\"\\n    with open(input_path, 'r') as f:\\n      return pd.read_csv(\\n          f,\\n          dtype={\\n              _QUERY_COL: str,\\n              _CORPUS_COL: str,\\n              _SCORE_COL: float,\\n          },\\n          delim_whitespace=True,\\n      ).fillna({_SCORE_COL: 1.0})\\n\\n  def _write_label_tsv(df: pd.DataFrame, output_path: str) -\\u003e str:\\n    \\\"\\\"\\\"Writes a label DataFrame to a TSV file.\\\"\\\"\\\"\\n    df.to_csv(output_path, index=False, sep='\\\\t')\\n    return output_path\\n\\n  def _get_positive_queries(labels: pd.DataFrame) -\\u003e pd.Series:\\n    \\\"\\\"\\\"Returns the queries that are part of a positive pair.\\\"\\\"\\\"\\n    return labels.loc[labels[_SCORE_COL] \\u003e 0.0, _QUERY_COL].unique()\\n\\n  def _validate_label_data_size(\\n      input_df: pd.DataFrame, label_path: str\\n  ) -\\u003e None:\\n    \\\"\\\"\\\"Validates that there are enough positive queries in the label data.\\\"\\\"\\\"\\n    unique_queries = _get_positive_queries(input_df)\\n    size_error_message = (\\n        f'Label data is too small. `{label_path}` should include a minimum of'\\n        f' {_MIN_LABELS_SIZE} unique `{_QUERY_COL}` entries with `{_SCORE_COL}`'\\n        f' \\u003e 0. Only {len(unique_queries)} positive queries were provided.'\\n    )\\n    if len(unique_queries) \\u003c _MIN_LABELS_SIZE:\\n      raise UserError(size_error_message)\\n\\n  def _autosplit_dataset(\\n      input_df: pd.DataFrame, test_percent: float\\n  ) -\\u003e Tuple[pd.DataFrame, pd.DataFrame]:\\n    \\\"\\\"\\\"Splits the data into (train, test) data with `test_percent` in test.\\\"\\\"\\\"\\n    input_df = input_df.sort_values(_QUERY_COL, ignore_index=True)\\n    unique_queries = _get_positive_queries(input_df)\\n    size_error_message = (\\n        'Label data is too small to autosplit with autosplitting ratio'\\n        f' ({test_percent}). Datasets should include a minimum of'\\n        f' {3*_MIN_LABELS_SIZE} unique `{_QUERY_COL}` entries with'\\n        f' `{_SCORE_COL}` \\u003e 0 in order to generate autosplit test or validation'\\n        f' sets. Only {len(unique_queries)} positive queries were provided.'\\n    )\\n    if len(unique_queries) \\u003c _MIN_LABELS_SIZE:\\n      raise UserError(size_error_message)\\n\\n    # Split by queries so as to not overlap between dataset splits.\\n    end_of_test_idx = math.floor(\\n        max(_MIN_LABELS_SIZE, len(unique_queries) * test_percent) - 1\\n    )\\n    last_test_query = unique_queries[end_of_test_idx]\\n    test_end = input_df[_QUERY_COL].searchsorted(last_test_query, side='right')\\n\\n    test_data = input_df.iloc[:test_end].reset_index(drop=True)\\n    train_data = input_df.iloc[test_end:].reset_index(drop=True)\\n\\n    if min(len(train_data), len(test_data)) \\u003c _MIN_LABELS_SIZE:\\n      raise UserError(size_error_message)\\n    return train_data, test_data\\n\\n  def _generate_validation_and_test_labels(\\n      train_label_path: str,\\n      validation_label_path: str = '',\\n      test_label_path: str = '',\\n  ) -\\u003e Tuple[str, str, str]:\\n    \\\"\\\"\\\"Splits out test and validation labels if they do not exist.\\\"\\\"\\\"\\n    # Normalize all paths to be readable by `open()`.\\n    train_label_path = typing.cast(str, _to_gcs_fuse(train_label_path))\\n    validation_label_path = _to_gcs_fuse(validation_label_path)\\n    test_label_path = _to_gcs_fuse(test_label_path)\\n\\n    input_train_data = _read_label_tsv(train_label_path)\\n    input_test_data = (\\n        _read_label_tsv(test_label_path) if test_label_path else None\\n    )\\n    input_validation_data = (\\n        _read_label_tsv(validation_label_path)\\n        if validation_label_path\\n        else None\\n    )\\n\\n    # Autosplit test from train, then validation from remaining train.\\n    if input_test_data is None:\\n      input_train_data, autosplit_test_data = _autosplit_dataset(\\n          input_train_data, test_autosplit_ratio\\n      )\\n      test_label_path = _write_label_tsv(autosplit_test_data, _TEST_OUT)\\n    else:\\n      _validate_label_data_size(input_test_data, test_label_path)\\n\\n    if input_validation_data is None:\\n      input_train_data, autosplit_validation_data = _autosplit_dataset(\\n          input_train_data, validation_autosplit_ratio\\n      )\\n      validation_label_path = _write_label_tsv(\\n          autosplit_validation_data, _VALIDATION_OUT\\n      )\\n    else:\\n      _validate_label_data_size(input_validation_data, validation_label_path)\\n\\n    _validate_label_data_size(input_train_data, train_label_path)\\n\\n    if input_validation_data is None or input_test_data is None:\\n      # This implies the train data has been shrunk, so we should write out the\\n      # modified version.\\n      train_label_path = _write_label_tsv(input_train_data, _TRAIN_OUT)\\n\\n    # Hyperlinks are autogenerated for gs:// paths in the Vertex Pipelines UI.\\n    return (\\n        _to_gs_doubleslash(train_label_path),\\n        _to_gs_doubleslash(validation_label_path),\\n        _to_gs_doubleslash(test_label_path),\\n    )\\n\\n  @raise_user_error_on_failure\\n  def _validate_jsonl_file_size(\\n      jsonl_path: str, file_description: str, min_size: int, max_size: int\\n  ) -\\u003e None:\\n    \\\"\\\"\\\"Validates that the number of queries or corpus is not too large.\\\"\\\"\\\"\\n    with open(_to_gcs_fuse(jsonl_path), 'r') as f:\\n      num_lines = sum(1 for _line in f)\\n      if num_lines not in range(min_size, max_size + 1):\\n        raise UserError(\\n            f'Invalid number of entries in JSONL file {jsonl_path}. Each'\\n            f' {file_description} file must have between {min_size} and'\\n            f' {max_size} entries.'\\n        )\\n\\n  def _get_model_template_name(\\n      base_model_version_id: str, allowed_model_ids: Container[str]\\n  ) -\\u003e str:\\n    \\\"\\\"\\\"Returns the model template name used for the LLM trainer.\\\"\\\"\\\"\\n    if base_model_version_id not in allowed_model_ids:\\n      raise UserError(\\n          'This pipeline does not allow tuning for model version'\\n          f' {base_model_version_id}. Note that tuning for `latest` versions is'\\n          ' not supported at this time. Allowed model versions:'\\n          f' {allowed_model_ids}'\\n      )\\n    parts = base_model_version_id.split('@')\\n    if len(parts) != 2:\\n      raise UserError(\\n          'The base model version ID must include the model ID and the version'\\n          ' ID, separated by \\\"@\\\", for example \\\"textembedding-gecko@001\\\". Given'\\n          f' \\\"{base_model_version_id}\\\".'\\n      )\\n    model, version = parts\\n    if model == 'textembedding-gecko-multilingual':\\n      return f'TEXT_EMBEDDING_GECKO_MULTILINGUAL_{version.upper()}'\\n    else:\\n      return f'TEXT_EMBEDDING_GECKO_{version.upper()}'\\n\\n  def _validate_task_type(task_type: str, base_model_version_id: str) -\\u003e None:\\n    \\\"\\\"\\\"Verify the task type is valid.\\\"\\\"\\\"\\n    # task_type may be '', which is fine.\\n    if not task_type:\\n      return\\n    elif task_type not in _ALL_TASK_TYPES:\\n      raise UserError(\\n          f'task_type must be one of [{\\\", \\\".join(_ALL_TASK_TYPES)}]. Given:'\\n          f' {task_type}'\\n      )\\n    elif (\\n        base_model_version_id == _GECKO_001_MODEL_ID and task_type != 'DEFAULT'\\n    ):\\n      raise UserError(\\n          f'task_type cannot be specified for model {_GECKO_001_MODEL_ID}.'\\n          f' Given: {task_type}'\\n      )\\n\\n  try:\\n    # [Beginning of main component logic.]\\n    if not (train_label_path and query_jsonl_path and corpus_jsonl_path):\\n      raise UserError(\\n          'Train labels, queries in JSONL, and corpus in JSONL, are all'\\n          ' required.'\\n      )\\n    _validate_task_type(task_type, base_model_version_id)\\n    template_name = _get_model_template_name(\\n        base_model_version_id, allowed_model_ids\\n    )\\n    _validate_jsonl_file_size(query_jsonl_path, 'query', _MIN_QUERY, _MAX_QUERY)\\n    _validate_jsonl_file_size(\\n        corpus_jsonl_path, 'corpus', _MIN_CORPUS, _MAX_CORPUS\\n    )\\n    train_label_path, validation_label_path, test_label_path = (\\n        _generate_validation_and_test_labels(\\n            train_label_path, validation_label_path, test_label_path\\n        )\\n    )\\n    return ValidationOutput(\\n        model_upload_labels={\\n            'google-vertex-llm-tuning-base-model-id': (\\n                base_model_version_id.replace('@', '-')\\n            )\\n        },\\n        train_tsv=train_label_path,\\n        test_tsv=test_label_path,\\n        validation_tsv=validation_label_path,\\n        llm_model_template_name=template_name,\\n    )\\n  except Exception as e:  # pylint: disable=broad-exception-caught\\n    if isinstance(e, UserError):\\n      raise\\n    logging.exception(str(e))\\n    # Exit code 13 signals that the component has encountered an \\\"internal\\\"\\n    # error, which counts against this component's SLO.\\n    sys.exit(13)\\n\\n\"\n",
      "            ],\n",
      "            \"args\": [\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--function_to_execute\",\n",
      "              \"text_embedding_autosplitter\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"exec-text-embedding-evaluator\": {\n",
      "          \"container\": {\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.0.0b3\",\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.custom_job.launcher\"\n",
      "            ],\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"CustomJob\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"Concat\\\": [\\\"{\\\", \\\"\\\\\\\"display_name\\\\\\\": \\\\\\\"Text_Embedding_Evaluator_{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"encryption_spec_key_name\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"encryption_spec\\\\\\\": {\\\", \\\"\\\\\\\"kms_key_name\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['encryption_spec_key_name']}}\\\", \\\"\\\\\\\"\\\", \\\"},\\\"]}}}, \\\"\\\\\\\"job_spec\\\\\\\": {\\\", \\\"\\\\\\\"worker_pool_specs\\\\\\\": [\\\", \\\"{\\\", \\\"\\\\\\\"machine_spec\\\\\\\": {\\\", \\\"\\\\\\\"machine_type\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['machine_type']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"accelerator_type\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['accelerator_type']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"accelerator_count\\\\\\\": \\\", \\\"{{$.inputs.parameters['accelerator_count']}}\\\", \\\"},\\\", \\\"\\\\\\\"replica_count\\\\\\\": 1,\\\", \\\"\\\\\\\"disk_spec\\\\\\\": {\\\", \\\"\\\\\\\"boot_disk_type\\\\\\\": \\\\\\\"pd-ssd\\\\\\\",\\\", \\\"\\\\\\\"boot_disk_size_gb\\\\\\\": 100\\\", \\\"},\\\", \\\"\\\\\\\"container_spec\\\\\\\": {\\\", \\\"\\\\\\\"image_uri\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['image_uri']}}\\\", \\\"\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"aip_private_bucket_name\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"env\\\\\\\": [\\\", \\\"{\\\", \\\"\\\\\\\"name\\\\\\\": \\\\\\\"AIP_PRIVATE_BUCKET_NAME\\\\\\\",\\\", \\\"\\\\\\\"value\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['aip_private_bucket_name']}}\\\", \\\"\\\\\\\"\\\", \\\"}\\\", \\\"],\\\"]}}}, \\\"\\\\\\\"args\\\\\\\": [\\\", \\\"\\\\\\\"--queries_path=\\\", \\\"{{$.inputs.parameters['queries_path']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--corpus_path=\\\", \\\"{{$.inputs.parameters['corpus_path']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--validation_label_path=\\\", \\\"{{$.inputs.parameters['validation_label_path']}}\\\", \\\"\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"train_graph_saved_model_path\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--train_graph_saved_model_path=\\\", \\\"{{$.inputs.artifacts['train_graph_saved_model_path'].path}}\\\", \\\"\\\\\\\",\\\"]}}}, \\\"\\\\\\\"--auxiliary_trainer_saved_model_path=\\\", \\\"{{$.inputs.artifacts['auxiliary_trainer_saved_model_path'].path}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--test_label_path=\\\", \\\"{{$.inputs.parameters['test_label_path']}}\\\", \\\"\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"base_model_version_id\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--base_model_version_id=\\\", \\\"{{$.inputs.parameters['base_model_version_id']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"task_type\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--task_type=\\\", \\\"{{$.inputs.parameters['task_type']}}\\\", \\\"\\\\\\\",\\\"]}}}, \\\"\\\\\\\"--executor_input={{$.json_escape[1]}}\\\\\\\"\\\", \\\"]\\\", \\\"}\\\", \\\"}\\\", \\\"],\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"service_account\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"service_account\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"network\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"network\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['network']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"reserved_ip_ranges\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"reserved_ip_ranges\\\\\\\": \\\", \\\"{{$.inputs.parameters['reserved_ip_ranges']}}\\\"]}}}, \\\"\\\\\\\"enable_web_access\\\\\\\": false\\\", \\\"}\\\", \\\"}\\\"]}\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"exec-text-embedding-model-uploader\": {\n",
      "          \"container\": {\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.3.1\",\n",
      "            \"command\": [\n",
      "              \"sh\",\n",
      "              \"-ec\",\n",
      "              \"program_path=$(mktemp -d)\\n\\nprintf \\\"%s\\\" \\\"$0\\\" \\u003e \\\"$program_path/ephemeral_component.py\\\"\\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \\\"$program_path/ephemeral_component.py\\\"                         \\\"$@\\\"\\n\",\n",
      "              \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import *\\n\\ndef text_embedding_model_uploader(\\n    project: str,\\n    location: str,\\n    artifact_uri: dsl.Input[dsl.Artifact],\\n    model_reference_name: str,\\n    model_display_name: str,\\n    regional_endpoint: str,\\n    model_resource_name: dsl.OutputPath(str),\\n    gcp_resources: dsl.OutputPath(str),\\n    encryption_spec_key_name: str = '',\\n    upload_model: bool = True,\\n):\\n  \\\"\\\"\\\"Uploads tuned text embedding model.\\n\\n  Args:\\n      project: Name of the GCP project.\\n      location: Location for model upload and deployment.\\n      artifact_uri: KFP Artifact for adapter.\\n      model_reference_name: Large model reference name.\\n      model_display_name: Name of the model (shown in Model Registry).\\n      regional_endpoint: Regional API endpoint.\\n      encryption_spec_key_name: Customer-managed encryption key.\\n      upload_model: Whether to upload the model to the Model Registry. Default\\n        is ``True``. If ``False``, the model will not be uploaded and output\\n        artifacts will contain empty strings.\\n\\n  Returns:\\n      model_resource_name: Path to the created Model on Model Registry.\\n      gcp_resources: Serialized JSON of `gcp_resources`.\\n  \\\"\\\"\\\"\\n  import json\\n  import logging\\n  import os\\n  import sys\\n\\n  try:\\n    from google_cloud_pipeline_components.container.v1.gcp_launcher import lro_remote_runner\\n  except ImportError:\\n    from google_cloud_pipeline_components.google_cloud_pipeline_components.container.v1.gcp_launcher import lro_remote_runner\\n\\n  try:\\n    os.makedirs(os.path.dirname(model_resource_name), exist_ok=True)\\n\\n    if not upload_model:\\n      with open(model_resource_name, 'w') as fout:\\n        fout.write('')\\n      return\\n\\n    pipeline_labels_str = os.getenv('VERTEX_AI_PIPELINES_RUN_LABELS')\\n    labels = json.loads(pipeline_labels_str) if pipeline_labels_str else {}\\n    labels['google-vertex-llm-tuning-base-model-id'] = (\\n        model_reference_name.replace('@', '-')\\n    )\\n\\n    model_upload_payload = {\\n        'model': {\\n            'artifactUri': artifact_uri.uri,\\n            'containerSpec': {\\n                'imageUri': 'us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.2-11:latest'\\n            },\\n            'displayName': model_display_name,\\n            'generatedModelSource': {\\n                'model_garden_source': {\\n                    'public_model_name': 'tuned-text-embedding-model'\\n                }\\n            },\\n            'labels': labels,\\n        }\\n    }\\n    if encryption_spec_key_name:\\n      model_upload_payload['model']['encryption_spec'] = {\\n          'kms_key_name': encryption_spec_key_name\\n      }\\n\\n    upload_model_uri = (\\n        f'{regional_endpoint.rstrip(\\\"/\\\")}/'\\n        f'projects/{project}/locations/{location}/models:upload'\\n    )\\n\\n    remote_runner = lro_remote_runner.LroRemoteRunner(location)\\n    upload_model_lro = remote_runner.create_lro(\\n        upload_model_uri,\\n        json.dumps(model_upload_payload),\\n        gcp_resources,\\n    )\\n    upload_model_lro = remote_runner.poll_lro(lro=upload_model_lro)\\n    model_resource = upload_model_lro['response']['model']\\n    model_version_id = upload_model_lro['response'].get(\\n        'model_version_id'\\n    ) or upload_model_lro['response'].get('modelVersionId')\\n    if model_version_id:\\n      model_resource += f'@{model_version_id}'\\n\\n    with open(model_resource_name, 'w') as fout:\\n      fout.write(model_resource)\\n\\n  except Exception as e:  # pylint: disable=broad-exception-caught\\n    if isinstance(e, ValueError):\\n      raise\\n    logging.exception(str(e))\\n    sys.exit(13)\\n\\n\"\n",
      "            ],\n",
      "            \"args\": [\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--function_to_execute\",\n",
      "              \"text_embedding_model_uploader\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"exec-text-embedding-trainer\": {\n",
      "          \"container\": {\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.0.0b3\",\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.custom_job.launcher\"\n",
      "            ],\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"CustomJob\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"Concat\\\": [\\\"{\\\", \\\"\\\\\\\"display_name\\\\\\\": \\\\\\\"Text_Embedding_Trainer_{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"encryption_spec_key_name\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"encryption_spec\\\\\\\": {\\\", \\\"\\\\\\\"kms_key_name\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['encryption_spec_key_name']}}\\\", \\\"\\\\\\\"\\\", \\\"},\\\"]}}}, \\\"\\\\\\\"job_spec\\\\\\\": {\\\", \\\"\\\\\\\"worker_pool_specs\\\\\\\": [\\\", \\\"{\\\", \\\"\\\\\\\"machine_spec\\\\\\\": {\\\", \\\"\\\\\\\"machine_type\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['machine_type']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"accelerator_type\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['accelerator_type']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"accelerator_count\\\\\\\": \\\", \\\"{{$.inputs.parameters['accelerator_count']}}\\\", \\\"},\\\", \\\"\\\\\\\"replica_count\\\\\\\": \\\", \\\"{{$.inputs.parameters['replica_count']}}\\\", \\\",\\\", \\\"\\\\\\\"disk_spec\\\\\\\": {\\\", \\\"\\\\\\\"boot_disk_type\\\\\\\": \\\\\\\"pd-ssd\\\\\\\",\\\", \\\"\\\\\\\"boot_disk_size_gb\\\\\\\": 100\\\", \\\"},\\\", \\\"\\\\\\\"container_spec\\\\\\\": {\\\", \\\"\\\\\\\"image_uri\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['image_uri']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"args\\\\\\\": [\\\", \\\"\\\\\\\"--queries_path=\\\", \\\"{{$.inputs.parameters['queries_path']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--corpus_path=\\\", \\\"{{$.inputs.parameters['corpus_path']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--train_label_path=\\\", \\\"{{$.inputs.parameters['train_label_path']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--run_evaluation_and_final_export=\\\", \\\"{{$.inputs.parameters['run_evaluation_and_final_export']}}\\\", \\\"\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"validation_label_path\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--validation_label_path=\\\", \\\"{{$.inputs.parameters['validation_label_path']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"test_label_path\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--test_label_path=\\\", \\\"{{$.inputs.parameters['test_label_path']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"base_model_version_id\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--base_model_version_id=\\\", \\\"{{$.inputs.parameters['base_model_version_id']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"task_type\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--task_type=\\\", \\\"{{$.inputs.parameters['task_type']}}\\\", \\\"\\\\\\\",\\\"]}}}, \\\"\\\\\\\"--batch_size=\\\", \\\"{{$.inputs.parameters['batch_size']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--iterations=\\\", \\\"{{$.inputs.parameters['iterations']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--executor_input={{$.json_escape[1]}}\\\\\\\"\\\", \\\"]\\\", \\\"}\\\", \\\"}\\\", \\\"],\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"service_account\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"service_account\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"network\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"network\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['network']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"reserved_ip_ranges\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"reserved_ip_ranges\\\\\\\": \\\", \\\"{{$.inputs.parameters['reserved_ip_ranges']}}\\\", \\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"tensorboard\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"tensorboard\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['tensorboard']}}\\\", \\\"\\\\\\\",\\\"]}}}, \\\"\\\\\\\"enable_web_access\\\\\\\": false\\\", \\\"}\\\", \\\"}\\\"]}\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"components\": {\n",
      "      \"comp-text-embedding-autosplitter\": {\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"allowed_model_ids\": {\n",
      "              \"parameterType\": \"LIST\"\n",
      "            },\n",
      "            \"base_model_version_id\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"corpus_jsonl_path\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"query_jsonl_path\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"task_type\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"defaultValue\": \"DEFAULT\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"test_autosplit_ratio\": {\n",
      "              \"parameterType\": \"NUMBER_DOUBLE\",\n",
      "              \"defaultValue\": 0.2,\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"test_label_path\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"defaultValue\": \"\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"train_label_path\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"validation_autosplit_ratio\": {\n",
      "              \"parameterType\": \"NUMBER_DOUBLE\",\n",
      "              \"defaultValue\": 0.2,\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"validation_label_path\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"defaultValue\": \"\",\n",
      "              \"isOptional\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"autosplitting_output\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Dataset\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"parameters\": {\n",
      "            \"llm_model_template_name\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"model_upload_labels\": {\n",
      "              \"parameterType\": \"STRUCT\"\n",
      "            },\n",
      "            \"test_tsv\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"train_tsv\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"validation_tsv\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"executorLabel\": \"exec-text-embedding-autosplitter\"\n",
      "      },\n",
      "      \"comp-text-embedding-evaluator\": {\n",
      "        \"inputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"auxiliary_trainer_saved_model_path\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Artifact\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            },\n",
      "            \"train_graph_saved_model_path\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Artifact\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              },\n",
      "              \"isOptional\": true\n",
      "            }\n",
      "          },\n",
      "          \"parameters\": {\n",
      "            \"accelerator_count\": {\n",
      "              \"parameterType\": \"NUMBER_INTEGER\",\n",
      "              \"defaultValue\": 4,\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"accelerator_type\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"defaultValue\": \"NVIDIA_TESLA_V100\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"aip_private_bucket_name\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"base_model_version_id\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"corpus_path\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"encryption_spec_key_name\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"image_uri\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"defaultValue\": \"us-central1\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"machine_type\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"defaultValue\": \"n1-standard-16\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"network\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"queries_path\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"reserved_ip_ranges\": {\n",
      "              \"parameterType\": \"LIST\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"task_type\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"test_label_path\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"validation_label_path\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"metrics\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Artifact\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            },\n",
      "            \"saved_model\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Artifact\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"executorLabel\": \"exec-text-embedding-evaluator\"\n",
      "      },\n",
      "      \"comp-text-embedding-model-uploader\": {\n",
      "        \"inputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"artifact_uri\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Artifact\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              },\n",
      "              \"description\": \"KFP Artifact for adapter.\"\n",
      "            }\n",
      "          },\n",
      "          \"parameters\": {\n",
      "            \"encryption_spec_key_name\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"defaultValue\": \"\",\n",
      "              \"isOptional\": true,\n",
      "              \"description\": \"Customer-managed encryption key.\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"description\": \"Location for model upload and deployment.\"\n",
      "            },\n",
      "            \"model_display_name\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"description\": \"Name of the model (shown in Model Registry).\"\n",
      "            },\n",
      "            \"model_reference_name\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"description\": \"Large model reference name.\"\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"description\": \"Name of the GCP project.\"\n",
      "            },\n",
      "            \"regional_endpoint\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"description\": \"Regional API endpoint.\"\n",
      "            },\n",
      "            \"upload_model\": {\n",
      "              \"parameterType\": \"BOOLEAN\",\n",
      "              \"defaultValue\": true,\n",
      "              \"isOptional\": true,\n",
      "              \"description\": \"Whether to upload the model to the Model Registry. Default\\nis ``True``. If ``False``, the model will not be uploaded and output\\nartifacts will contain empty strings.\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"description\": \"Serialized JSON of `gcp_resources`.\"\n",
      "            },\n",
      "            \"model_resource_name\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"description\": \"Path to the created Model on Model Registry.\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"executorLabel\": \"exec-text-embedding-model-uploader\"\n",
      "      },\n",
      "      \"comp-text-embedding-trainer\": {\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"accelerator_count\": {\n",
      "              \"parameterType\": \"NUMBER_INTEGER\",\n",
      "              \"defaultValue\": 4,\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"accelerator_type\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"defaultValue\": \"NVIDIA_TESLA_V100\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"base_model_version_id\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"batch_size\": {\n",
      "              \"parameterType\": \"NUMBER_INTEGER\"\n",
      "            },\n",
      "            \"corpus_path\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"encryption_spec_key_name\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"image_uri\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"iterations\": {\n",
      "              \"parameterType\": \"NUMBER_INTEGER\"\n",
      "            },\n",
      "            \"location\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"defaultValue\": \"us-central1\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"machine_type\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"defaultValue\": \"n1-standard-16\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"network\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"project\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"queries_path\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"replica_count\": {\n",
      "              \"parameterType\": \"NUMBER_INTEGER\",\n",
      "              \"defaultValue\": 1,\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"reserved_ip_ranges\": {\n",
      "              \"parameterType\": \"LIST\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"run_evaluation_and_final_export\": {\n",
      "              \"parameterType\": \"BOOLEAN\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"service_account\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"task_type\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"tensorboard\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"test_label_path\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            },\n",
      "            \"train_label_path\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            },\n",
      "            \"validation_label_path\": {\n",
      "              \"parameterType\": \"STRING\",\n",
      "              \"isOptional\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"outputDefinitions\": {\n",
      "          \"artifacts\": {\n",
      "            \"metrics\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Artifact\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            },\n",
      "            \"saved_model\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Artifact\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            },\n",
      "            \"training_output\": {\n",
      "              \"artifactType\": {\n",
      "                \"schemaTitle\": \"system.Artifact\",\n",
      "                \"schemaVersion\": \"0.0.1\"\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"parameters\": {\n",
      "            \"gcp_resources\": {\n",
      "              \"parameterType\": \"STRING\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"executorLabel\": \"exec-text-embedding-trainer\"\n",
      "      }\n",
      "    },\n",
      "    \"schemaVersion\": \"2.1.0\",\n",
      "    \"root\": {\n",
      "      \"inputDefinitions\": {\n",
      "        \"parameters\": {\n",
      "          \"accelerator_count\": {\n",
      "            \"parameterType\": \"NUMBER_INTEGER\",\n",
      "            \"defaultValue\": 4,\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"how many accelerators to use when running the\\ncontainer.\"\n",
      "          },\n",
      "          \"accelerator_type\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"defaultValue\": \"NVIDIA_TESLA_V100\",\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"the accelerator type for running the trainer component.\"\n",
      "          },\n",
      "          \"base_model_version_id\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"defaultValue\": \"textembedding-gecko@001\",\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"which base model to tune. This may be any stable\\nnumbered version, for example `textembedding-gecko@001`.\"\n",
      "          },\n",
      "          \"batch_size\": {\n",
      "            \"parameterType\": \"NUMBER_INTEGER\",\n",
      "            \"defaultValue\": 128,\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"training batch size.\"\n",
      "          },\n",
      "          \"corpus_path\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"description\": \"the GCS path to the corpus data location.\"\n",
      "          },\n",
      "          \"iterations\": {\n",
      "            \"parameterType\": \"NUMBER_INTEGER\",\n",
      "            \"defaultValue\": 1000,\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"the number of steps to perform fine-tuning.\"\n",
      "          },\n",
      "          \"location\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"defaultValue\": \"us-central1\",\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"GCP region to run the pipeline.\"\n",
      "          },\n",
      "          \"machine_type\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"defaultValue\": \"n1-standard-16\",\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"the type of the machine to run the trainer component. For\\nmore details about this input config, see:\\nhttps://cloud.google.com/vertex-ai/docs/training/configure-compute.\"\n",
      "          },\n",
      "          \"model_display_name\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"defaultValue\": \"tuned-text-embedding-model\",\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"output model display name.\"\n",
      "          },\n",
      "          \"project\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"description\": \"user's project id.\"\n",
      "          },\n",
      "          \"queries_path\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"description\": \"the GCS path to the queries location.\"\n",
      "          },\n",
      "          \"task_type\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"defaultValue\": \"DEFAULT\",\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"the task type expected to be used during inference. Valid\\nvalues are `DEFAULT`, `RETRIEVAL_QUERY`, `RETRIEVAL_DOCUMENT`,\\n`SEMANTIC_SIMILARITY`, `CLASSIFICATION`, and `CLUSTERING`.\"\n",
      "          },\n",
      "          \"test_label_path\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"defaultValue\": \"\",\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"the GCS path to the test label data location.\"\n",
      "          },\n",
      "          \"train_label_path\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"description\": \"the GCS path to the train label data location.\"\n",
      "          },\n",
      "          \"validation_label_path\": {\n",
      "            \"parameterType\": \"STRING\",\n",
      "            \"defaultValue\": \"\",\n",
      "            \"isOptional\": true,\n",
      "            \"description\": \"The GCS path to the validation label data location.\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"dag\": {\n",
      "        \"tasks\": {\n",
      "          \"text-embedding-autosplitter\": {\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"text-embedding-autosplitter\"\n",
      "            },\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"allowed_model_ids\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constant\": [\n",
      "                      \"textembedding-gecko@001\",\n",
      "                      \"textembedding-gecko@002\",\n",
      "                      \"textembedding-gecko@003\",\n",
      "                      \"textembedding-gecko-multilingual@001\"\n",
      "                    ]\n",
      "                  }\n",
      "                },\n",
      "                \"base_model_version_id\": {\n",
      "                  \"componentInputParameter\": \"base_model_version_id\"\n",
      "                },\n",
      "                \"corpus_jsonl_path\": {\n",
      "                  \"componentInputParameter\": \"corpus_path\"\n",
      "                },\n",
      "                \"query_jsonl_path\": {\n",
      "                  \"componentInputParameter\": \"queries_path\"\n",
      "                },\n",
      "                \"task_type\": {\n",
      "                  \"componentInputParameter\": \"task_type\"\n",
      "                },\n",
      "                \"test_label_path\": {\n",
      "                  \"componentInputParameter\": \"test_label_path\"\n",
      "                },\n",
      "                \"train_label_path\": {\n",
      "                  \"componentInputParameter\": \"train_label_path\"\n",
      "                },\n",
      "                \"validation_label_path\": {\n",
      "                  \"componentInputParameter\": \"validation_label_path\"\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"cachingOptions\": {\n",
      "              \"enableCache\": true\n",
      "            },\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-text-embedding-autosplitter\"\n",
      "            }\n",
      "          },\n",
      "          \"text-embedding-evaluator\": {\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"text-embedding-evaluator\"\n",
      "            },\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"accelerator_count\": {\n",
      "                  \"componentInputParameter\": \"accelerator_count\"\n",
      "                },\n",
      "                \"accelerator_type\": {\n",
      "                  \"componentInputParameter\": \"accelerator_type\"\n",
      "                },\n",
      "                \"base_model_version_id\": {\n",
      "                  \"componentInputParameter\": \"base_model_version_id\"\n",
      "                },\n",
      "                \"corpus_path\": {\n",
      "                  \"componentInputParameter\": \"corpus_path\"\n",
      "                },\n",
      "                \"image_uri\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constant\": \"us-docker.pkg.dev/vertex-ai-restricted/builtin-algorithm/custom_embedding_postprocessor:v1.1.1\"\n",
      "                  }\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"machine_type\": {\n",
      "                  \"componentInputParameter\": \"machine_type\"\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project\"\n",
      "                },\n",
      "                \"queries_path\": {\n",
      "                  \"componentInputParameter\": \"queries_path\"\n",
      "                },\n",
      "                \"task_type\": {\n",
      "                  \"componentInputParameter\": \"task_type\"\n",
      "                },\n",
      "                \"test_label_path\": {\n",
      "                  \"taskOutputParameter\": {\n",
      "                    \"producerTask\": \"text-embedding-autosplitter\",\n",
      "                    \"outputParameterKey\": \"test_tsv\"\n",
      "                  }\n",
      "                },\n",
      "                \"validation_label_path\": {\n",
      "                  \"taskOutputParameter\": {\n",
      "                    \"producerTask\": \"text-embedding-autosplitter\",\n",
      "                    \"outputParameterKey\": \"validation_tsv\"\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"artifacts\": {\n",
      "                \"auxiliary_trainer_saved_model_path\": {\n",
      "                  \"taskOutputArtifact\": {\n",
      "                    \"producerTask\": \"text-embedding-trainer\",\n",
      "                    \"outputArtifactKey\": \"saved_model\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"text-embedding-autosplitter\",\n",
      "              \"text-embedding-trainer\"\n",
      "            ],\n",
      "            \"cachingOptions\": {\n",
      "              \"enableCache\": true\n",
      "            },\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-text-embedding-evaluator\"\n",
      "            }\n",
      "          },\n",
      "          \"text-embedding-model-uploader\": {\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"text-embedding-model-uploader\"\n",
      "            },\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"model_display_name\": {\n",
      "                  \"componentInputParameter\": \"model_display_name\"\n",
      "                },\n",
      "                \"model_reference_name\": {\n",
      "                  \"componentInputParameter\": \"base_model_version_id\"\n",
      "                },\n",
      "                \"pipelinechannel--location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project\"\n",
      "                },\n",
      "                \"regional_endpoint\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constant\": \"https://{{$.inputs.parameters['pipelinechannel--location']}}-aiplatform.googleapis.com/ui\"\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"artifacts\": {\n",
      "                \"artifact_uri\": {\n",
      "                  \"taskOutputArtifact\": {\n",
      "                    \"producerTask\": \"text-embedding-evaluator\",\n",
      "                    \"outputArtifactKey\": \"saved_model\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"text-embedding-evaluator\"\n",
      "            ],\n",
      "            \"cachingOptions\": {\n",
      "              \"enableCache\": true\n",
      "            },\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-text-embedding-model-uploader\"\n",
      "            }\n",
      "          },\n",
      "          \"text-embedding-trainer\": {\n",
      "            \"taskInfo\": {\n",
      "              \"name\": \"text-embedding-trainer\"\n",
      "            },\n",
      "            \"inputs\": {\n",
      "              \"parameters\": {\n",
      "                \"accelerator_count\": {\n",
      "                  \"componentInputParameter\": \"accelerator_count\"\n",
      "                },\n",
      "                \"accelerator_type\": {\n",
      "                  \"componentInputParameter\": \"accelerator_type\"\n",
      "                },\n",
      "                \"base_model_version_id\": {\n",
      "                  \"componentInputParameter\": \"base_model_version_id\"\n",
      "                },\n",
      "                \"batch_size\": {\n",
      "                  \"componentInputParameter\": \"batch_size\"\n",
      "                },\n",
      "                \"corpus_path\": {\n",
      "                  \"componentInputParameter\": \"corpus_path\"\n",
      "                },\n",
      "                \"image_uri\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constant\": \"us-docker.pkg.dev/vertex-ai-restricted/builtin-algorithm/custom_embedding_trainer_private:v1.1.1\"\n",
      "                  }\n",
      "                },\n",
      "                \"iterations\": {\n",
      "                  \"componentInputParameter\": \"iterations\"\n",
      "                },\n",
      "                \"location\": {\n",
      "                  \"componentInputParameter\": \"location\"\n",
      "                },\n",
      "                \"machine_type\": {\n",
      "                  \"componentInputParameter\": \"machine_type\"\n",
      "                },\n",
      "                \"project\": {\n",
      "                  \"componentInputParameter\": \"project\"\n",
      "                },\n",
      "                \"queries_path\": {\n",
      "                  \"componentInputParameter\": \"queries_path\"\n",
      "                },\n",
      "                \"run_evaluation_and_final_export\": {\n",
      "                  \"runtimeValue\": {\n",
      "                    \"constant\": false\n",
      "                  }\n",
      "                },\n",
      "                \"task_type\": {\n",
      "                  \"componentInputParameter\": \"task_type\"\n",
      "                },\n",
      "                \"test_label_path\": {\n",
      "                  \"taskOutputParameter\": {\n",
      "                    \"producerTask\": \"text-embedding-autosplitter\",\n",
      "                    \"outputParameterKey\": \"test_tsv\"\n",
      "                  }\n",
      "                },\n",
      "                \"train_label_path\": {\n",
      "                  \"taskOutputParameter\": {\n",
      "                    \"producerTask\": \"text-embedding-autosplitter\",\n",
      "                    \"outputParameterKey\": \"train_tsv\"\n",
      "                  }\n",
      "                },\n",
      "                \"validation_label_path\": {\n",
      "                  \"taskOutputParameter\": {\n",
      "                    \"producerTask\": \"text-embedding-autosplitter\",\n",
      "                    \"outputParameterKey\": \"validation_tsv\"\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"dependentTasks\": [\n",
      "              \"text-embedding-autosplitter\"\n",
      "            ],\n",
      "            \"cachingOptions\": {\n",
      "              \"enableCache\": true\n",
      "            },\n",
      "            \"componentRef\": {\n",
      "              \"name\": \"comp-text-embedding-trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"sdkVersion\": \"kfp-2.6.0\",\n",
      "    \"pipelineInfo\": {\n",
      "      \"name\": \"tune-text-embedding-model\",\n",
      "      \"description\": \"Pipeline definition for v1.1.x embedding tuning pipelines.\"\n",
      "    },\n",
      "    \"deploymentSpec\": {\n",
      "      \"executors\": {\n",
      "        \"exec-text-embedding-autosplitter\": {\n",
      "          \"container\": {\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.3.1\",\n",
      "            \"command\": [\n",
      "              \"sh\",\n",
      "              \"-ec\",\n",
      "              \"program_path=$(mktemp -d)\\n\\nprintf \\\"%s\\\" \\\"$0\\\" \\u003e \\\"$program_path/ephemeral_component.py\\\"\\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \\\"$program_path/ephemeral_component.py\\\"                         \\\"$@\\\"\\n\",\n",
      "              \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import *\\n\\ndef text_embedding_autosplitter(\\n    base_model_version_id: str,\\n    allowed_model_ids: List[str],\\n    query_jsonl_path: str,\\n    corpus_jsonl_path: str,\\n    train_label_path: str,\\n    autosplitting_output: dsl.Output[dsl.Dataset],\\n    task_type: str = 'DEFAULT',\\n    test_label_path: str = '',\\n    validation_label_path: str = '',\\n    test_autosplit_ratio: float = 0.2,\\n    validation_autosplit_ratio: float = 0.2,\\n) -\\u003e NamedTuple(\\n    'ValidationOutput',\\n    [\\n        ('model_upload_labels', Dict[str, str]),\\n        ('train_tsv', str),\\n        ('test_tsv', str),\\n        ('validation_tsv', str),\\n        ('llm_model_template_name', str),\\n    ],\\n):\\n  \\\"\\\"\\\"Validates pipeline parameters, and autosplits test and validation data.\\n\\n  Args:\\n    base_model_version_id: The full public version ID of the embedding model to\\n      tune.\\n    allowed_model_ids: The list of valid version IDs. This parameter is provided\\n      by the pipeline definition.\\n    query_jsonl_path: The path to queries in JSONL format.\\n    corpus_jsonl_path: The path to the corpus in JSONL format.\\n    train_label_path: The path to training labels in TSV format.\\n    autosplitting_output: The directory to output the autosplit dataset.\\n      Autogenerated by Kubeflow.\\n    task_type: Which task to optimize the model for.\\n    test_label_path: Path to test labels in TSV format.\\n    validation_label_path: Path to validation labels in TSV format.\\n    test_autosplit_ratio: The percentage to split out for the test dataset, if\\n      `test_label_path` is not provided.\\n    validation_autosplit_ratio: The percentage to split out for the validation\\n      dataset, if `validation_label_path` is not provided.\\n\\n  Returns:\\n    A `NamedTuple` with the following properties:\\n      - `model_upload_labels`: A dictionary of labels, to be added to the Vertex\\n      Model.\\n      - `train_tsv`: Path to the train labels.\\n      - `test_tsv`: Path to the test labels.\\n      - `validation_tsv`: Path to the validation labels.\\n      - `llm_model_template_name`: The name of the model template to use for\\n      tuning.\\n\\n  Raises:\\n    A `ValueError` if the parameters or data cannot be read or are invalid. All\\n    internal exceptions trigger a `SystemExit` with code `13`.\\n  \\\"\\\"\\\"\\n  import collections\\n  import logging\\n  import math\\n  import os\\n  import pandas as pd\\n  import sys\\n  import typing\\n\\n  _MIN_LABELS_SIZE = 3\\n  _MIN_QUERY = 1\\n  _MIN_CORPUS = 1\\n  _MAX_QUERY = 40_000\\n  _MAX_CORPUS = 500_000\\n\\n  _QUERY_COL = 'query-id'\\n  _CORPUS_COL = 'corpus-id'\\n  _SCORE_COL = 'score'\\n\\n  _GCS_FUSE_PREFIX = '/gcs/'\\n  _GCS_PREFIX = 'gs://'\\n  _ALL_TASK_TYPES = (\\n      'DEFAULT',\\n      'RETRIEVAL_DOCUMENT',\\n      'RETRIEVAL_QUERY',\\n      'SEMANTIC_SIMILARITY',\\n      'CLUSTERING',\\n      'CLASSIFICATION',\\n  )\\n  _GECKO_001_MODEL_ID = 'textembedding-gecko@001'\\n\\n  class UserError(ValueError):\\n    \\\"\\\"\\\"Error signaling an issue with the supplied parameters or data.\\\"\\\"\\\"\\n\\n  def _to_gcs_fuse(path: Optional[str]) -\\u003e Optional[str]:\\n    \\\"\\\"\\\"Converts gs:// paths to /gcs/.\\\"\\\"\\\"\\n    return (\\n        path.replace(_GCS_PREFIX, _GCS_FUSE_PREFIX, 1)\\n        if path and path.startswith(_GCS_PREFIX)\\n        else path\\n    )\\n\\n  def _to_gs_doubleslash(path: str) -\\u003e str:\\n    \\\"\\\"\\\"Converts /gcs/ paths to gs://.\\\"\\\"\\\"\\n    return (\\n        path.replace(_GCS_FUSE_PREFIX, _GCS_PREFIX, 1)\\n        if path.startswith(_GCS_FUSE_PREFIX)\\n        else path\\n    )\\n\\n  # These paths will only be written to if the datasets do not already exist.\\n  _OUT_DIR = _to_gcs_fuse(autosplitting_output.uri)\\n  _TRAIN_OUT = os.path.join(_OUT_DIR, 'train_labels.tsv')\\n  _VALIDATION_OUT = os.path.join(_OUT_DIR, 'validation_labels.tsv')\\n  _TEST_OUT = os.path.join(_OUT_DIR, 'test_labels.tsv')\\n  os.makedirs(_OUT_DIR, exist_ok=True)\\n\\n  ValidationOutput = collections.namedtuple(\\n      'ValidationOutput',\\n      [\\n          'model_upload_labels',\\n          'train_tsv',\\n          'test_tsv',\\n          'validation_tsv',\\n          'llm_model_template_name',\\n      ],\\n  )\\n\\n  def raise_user_error_on_failure(fn):\\n    \\\"\\\"\\\"Wraps a function, reraising any thrown exception as a `UserError`.\\\"\\\"\\\"\\n\\n    def _inner(*args, **kwargs):\\n      try:\\n        return fn(*args, **kwargs)\\n      except Exception as e:  # pylint: disable=broad-exception-caught\\n        raise UserError(str(e)) from e\\n\\n    return _inner\\n\\n  @raise_user_error_on_failure\\n  def _read_label_tsv(input_path: str) -\\u003e pd.DataFrame:\\n    \\\"\\\"\\\"Reads label data (`query-id`, `corpus-id`, `score`) from TSV file.\\\"\\\"\\\"\\n    with open(input_path, 'r') as f:\\n      return pd.read_csv(\\n          f,\\n          dtype={\\n              _QUERY_COL: str,\\n              _CORPUS_COL: str,\\n              _SCORE_COL: float,\\n          },\\n          delim_whitespace=True,\\n      ).fillna({_SCORE_COL: 1.0})\\n\\n  def _write_label_tsv(df: pd.DataFrame, output_path: str) -\\u003e str:\\n    \\\"\\\"\\\"Writes a label DataFrame to a TSV file.\\\"\\\"\\\"\\n    df.to_csv(output_path, index=False, sep='\\\\t')\\n    return output_path\\n\\n  def _get_positive_queries(labels: pd.DataFrame) -\\u003e pd.Series:\\n    \\\"\\\"\\\"Returns the queries that are part of a positive pair.\\\"\\\"\\\"\\n    return labels.loc[labels[_SCORE_COL] \\u003e 0.0, _QUERY_COL].unique()\\n\\n  def _validate_label_data_size(\\n      input_df: pd.DataFrame, label_path: str\\n  ) -\\u003e None:\\n    \\\"\\\"\\\"Validates that there are enough positive queries in the label data.\\\"\\\"\\\"\\n    unique_queries = _get_positive_queries(input_df)\\n    size_error_message = (\\n        f'Label data is too small. `{label_path}` should include a minimum of'\\n        f' {_MIN_LABELS_SIZE} unique `{_QUERY_COL}` entries with `{_SCORE_COL}`'\\n        f' \\u003e 0. Only {len(unique_queries)} positive queries were provided.'\\n    )\\n    if len(unique_queries) \\u003c _MIN_LABELS_SIZE:\\n      raise UserError(size_error_message)\\n\\n  def _autosplit_dataset(\\n      input_df: pd.DataFrame, test_percent: float\\n  ) -\\u003e Tuple[pd.DataFrame, pd.DataFrame]:\\n    \\\"\\\"\\\"Splits the data into (train, test) data with `test_percent` in test.\\\"\\\"\\\"\\n    input_df = input_df.sort_values(_QUERY_COL, ignore_index=True)\\n    unique_queries = _get_positive_queries(input_df)\\n    size_error_message = (\\n        'Label data is too small to autosplit with autosplitting ratio'\\n        f' ({test_percent}). Datasets should include a minimum of'\\n        f' {3*_MIN_LABELS_SIZE} unique `{_QUERY_COL}` entries with'\\n        f' `{_SCORE_COL}` \\u003e 0 in order to generate autosplit test or validation'\\n        f' sets. Only {len(unique_queries)} positive queries were provided.'\\n    )\\n    if len(unique_queries) \\u003c _MIN_LABELS_SIZE:\\n      raise UserError(size_error_message)\\n\\n    # Split by queries so as to not overlap between dataset splits.\\n    end_of_test_idx = math.floor(\\n        max(_MIN_LABELS_SIZE, len(unique_queries) * test_percent) - 1\\n    )\\n    last_test_query = unique_queries[end_of_test_idx]\\n    test_end = input_df[_QUERY_COL].searchsorted(last_test_query, side='right')\\n\\n    test_data = input_df.iloc[:test_end].reset_index(drop=True)\\n    train_data = input_df.iloc[test_end:].reset_index(drop=True)\\n\\n    if min(len(train_data), len(test_data)) \\u003c _MIN_LABELS_SIZE:\\n      raise UserError(size_error_message)\\n    return train_data, test_data\\n\\n  def _generate_validation_and_test_labels(\\n      train_label_path: str,\\n      validation_label_path: str = '',\\n      test_label_path: str = '',\\n  ) -\\u003e Tuple[str, str, str]:\\n    \\\"\\\"\\\"Splits out test and validation labels if they do not exist.\\\"\\\"\\\"\\n    # Normalize all paths to be readable by `open()`.\\n    train_label_path = typing.cast(str, _to_gcs_fuse(train_label_path))\\n    validation_label_path = _to_gcs_fuse(validation_label_path)\\n    test_label_path = _to_gcs_fuse(test_label_path)\\n\\n    input_train_data = _read_label_tsv(train_label_path)\\n    input_test_data = (\\n        _read_label_tsv(test_label_path) if test_label_path else None\\n    )\\n    input_validation_data = (\\n        _read_label_tsv(validation_label_path)\\n        if validation_label_path\\n        else None\\n    )\\n\\n    # Autosplit test from train, then validation from remaining train.\\n    if input_test_data is None:\\n      input_train_data, autosplit_test_data = _autosplit_dataset(\\n          input_train_data, test_autosplit_ratio\\n      )\\n      test_label_path = _write_label_tsv(autosplit_test_data, _TEST_OUT)\\n    else:\\n      _validate_label_data_size(input_test_data, test_label_path)\\n\\n    if input_validation_data is None:\\n      input_train_data, autosplit_validation_data = _autosplit_dataset(\\n          input_train_data, validation_autosplit_ratio\\n      )\\n      validation_label_path = _write_label_tsv(\\n          autosplit_validation_data, _VALIDATION_OUT\\n      )\\n    else:\\n      _validate_label_data_size(input_validation_data, validation_label_path)\\n\\n    _validate_label_data_size(input_train_data, train_label_path)\\n\\n    if input_validation_data is None or input_test_data is None:\\n      # This implies the train data has been shrunk, so we should write out the\\n      # modified version.\\n      train_label_path = _write_label_tsv(input_train_data, _TRAIN_OUT)\\n\\n    # Hyperlinks are autogenerated for gs:// paths in the Vertex Pipelines UI.\\n    return (\\n        _to_gs_doubleslash(train_label_path),\\n        _to_gs_doubleslash(validation_label_path),\\n        _to_gs_doubleslash(test_label_path),\\n    )\\n\\n  @raise_user_error_on_failure\\n  def _validate_jsonl_file_size(\\n      jsonl_path: str, file_description: str, min_size: int, max_size: int\\n  ) -\\u003e None:\\n    \\\"\\\"\\\"Validates that the number of queries or corpus is not too large.\\\"\\\"\\\"\\n    with open(_to_gcs_fuse(jsonl_path), 'r') as f:\\n      num_lines = sum(1 for _line in f)\\n      if num_lines not in range(min_size, max_size + 1):\\n        raise UserError(\\n            f'Invalid number of entries in JSONL file {jsonl_path}. Each'\\n            f' {file_description} file must have between {min_size} and'\\n            f' {max_size} entries.'\\n        )\\n\\n  def _get_model_template_name(\\n      base_model_version_id: str, allowed_model_ids: Container[str]\\n  ) -\\u003e str:\\n    \\\"\\\"\\\"Returns the model template name used for the LLM trainer.\\\"\\\"\\\"\\n    if base_model_version_id not in allowed_model_ids:\\n      raise UserError(\\n          'This pipeline does not allow tuning for model version'\\n          f' {base_model_version_id}. Note that tuning for `latest` versions is'\\n          ' not supported at this time. Allowed model versions:'\\n          f' {allowed_model_ids}'\\n      )\\n    parts = base_model_version_id.split('@')\\n    if len(parts) != 2:\\n      raise UserError(\\n          'The base model version ID must include the model ID and the version'\\n          ' ID, separated by \\\"@\\\", for example \\\"textembedding-gecko@001\\\". Given'\\n          f' \\\"{base_model_version_id}\\\".'\\n      )\\n    model, version = parts\\n    if model == 'textembedding-gecko-multilingual':\\n      return f'TEXT_EMBEDDING_GECKO_MULTILINGUAL_{version.upper()}'\\n    else:\\n      return f'TEXT_EMBEDDING_GECKO_{version.upper()}'\\n\\n  def _validate_task_type(task_type: str, base_model_version_id: str) -\\u003e None:\\n    \\\"\\\"\\\"Verify the task type is valid.\\\"\\\"\\\"\\n    # task_type may be '', which is fine.\\n    if not task_type:\\n      return\\n    elif task_type not in _ALL_TASK_TYPES:\\n      raise UserError(\\n          f'task_type must be one of [{\\\", \\\".join(_ALL_TASK_TYPES)}]. Given:'\\n          f' {task_type}'\\n      )\\n    elif (\\n        base_model_version_id == _GECKO_001_MODEL_ID and task_type != 'DEFAULT'\\n    ):\\n      raise UserError(\\n          f'task_type cannot be specified for model {_GECKO_001_MODEL_ID}.'\\n          f' Given: {task_type}'\\n      )\\n\\n  try:\\n    # [Beginning of main component logic.]\\n    if not (train_label_path and query_jsonl_path and corpus_jsonl_path):\\n      raise UserError(\\n          'Train labels, queries in JSONL, and corpus in JSONL, are all'\\n          ' required.'\\n      )\\n    _validate_task_type(task_type, base_model_version_id)\\n    template_name = _get_model_template_name(\\n        base_model_version_id, allowed_model_ids\\n    )\\n    _validate_jsonl_file_size(query_jsonl_path, 'query', _MIN_QUERY, _MAX_QUERY)\\n    _validate_jsonl_file_size(\\n        corpus_jsonl_path, 'corpus', _MIN_CORPUS, _MAX_CORPUS\\n    )\\n    train_label_path, validation_label_path, test_label_path = (\\n        _generate_validation_and_test_labels(\\n            train_label_path, validation_label_path, test_label_path\\n        )\\n    )\\n    return ValidationOutput(\\n        model_upload_labels={\\n            'google-vertex-llm-tuning-base-model-id': (\\n                base_model_version_id.replace('@', '-')\\n            )\\n        },\\n        train_tsv=train_label_path,\\n        test_tsv=test_label_path,\\n        validation_tsv=validation_label_path,\\n        llm_model_template_name=template_name,\\n    )\\n  except Exception as e:  # pylint: disable=broad-exception-caught\\n    if isinstance(e, UserError):\\n      raise\\n    logging.exception(str(e))\\n    # Exit code 13 signals that the component has encountered an \\\"internal\\\"\\n    # error, which counts against this component's SLO.\\n    sys.exit(13)\\n\\n\"\n",
      "            ],\n",
      "            \"args\": [\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--function_to_execute\",\n",
      "              \"text_embedding_autosplitter\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"exec-text-embedding-evaluator\": {\n",
      "          \"container\": {\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.0.0b3\",\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.custom_job.launcher\"\n",
      "            ],\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"CustomJob\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"Concat\\\": [\\\"{\\\", \\\"\\\\\\\"display_name\\\\\\\": \\\\\\\"Text_Embedding_Evaluator_{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"encryption_spec_key_name\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"encryption_spec\\\\\\\": {\\\", \\\"\\\\\\\"kms_key_name\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['encryption_spec_key_name']}}\\\", \\\"\\\\\\\"\\\", \\\"},\\\"]}}}, \\\"\\\\\\\"job_spec\\\\\\\": {\\\", \\\"\\\\\\\"worker_pool_specs\\\\\\\": [\\\", \\\"{\\\", \\\"\\\\\\\"machine_spec\\\\\\\": {\\\", \\\"\\\\\\\"machine_type\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['machine_type']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"accelerator_type\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['accelerator_type']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"accelerator_count\\\\\\\": \\\", \\\"{{$.inputs.parameters['accelerator_count']}}\\\", \\\"},\\\", \\\"\\\\\\\"replica_count\\\\\\\": 1,\\\", \\\"\\\\\\\"disk_spec\\\\\\\": {\\\", \\\"\\\\\\\"boot_disk_type\\\\\\\": \\\\\\\"pd-ssd\\\\\\\",\\\", \\\"\\\\\\\"boot_disk_size_gb\\\\\\\": 100\\\", \\\"},\\\", \\\"\\\\\\\"container_spec\\\\\\\": {\\\", \\\"\\\\\\\"image_uri\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['image_uri']}}\\\", \\\"\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"aip_private_bucket_name\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"env\\\\\\\": [\\\", \\\"{\\\", \\\"\\\\\\\"name\\\\\\\": \\\\\\\"AIP_PRIVATE_BUCKET_NAME\\\\\\\",\\\", \\\"\\\\\\\"value\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['aip_private_bucket_name']}}\\\", \\\"\\\\\\\"\\\", \\\"}\\\", \\\"],\\\"]}}}, \\\"\\\\\\\"args\\\\\\\": [\\\", \\\"\\\\\\\"--queries_path=\\\", \\\"{{$.inputs.parameters['queries_path']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--corpus_path=\\\", \\\"{{$.inputs.parameters['corpus_path']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--validation_label_path=\\\", \\\"{{$.inputs.parameters['validation_label_path']}}\\\", \\\"\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"train_graph_saved_model_path\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--train_graph_saved_model_path=\\\", \\\"{{$.inputs.artifacts['train_graph_saved_model_path'].path}}\\\", \\\"\\\\\\\",\\\"]}}}, \\\"\\\\\\\"--auxiliary_trainer_saved_model_path=\\\", \\\"{{$.inputs.artifacts['auxiliary_trainer_saved_model_path'].path}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--test_label_path=\\\", \\\"{{$.inputs.parameters['test_label_path']}}\\\", \\\"\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"base_model_version_id\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--base_model_version_id=\\\", \\\"{{$.inputs.parameters['base_model_version_id']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"task_type\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--task_type=\\\", \\\"{{$.inputs.parameters['task_type']}}\\\", \\\"\\\\\\\",\\\"]}}}, \\\"\\\\\\\"--executor_input={{$.json_escape[1]}}\\\\\\\"\\\", \\\"]\\\", \\\"}\\\", \\\"}\\\", \\\"],\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"service_account\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"service_account\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"network\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"network\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['network']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"reserved_ip_ranges\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"reserved_ip_ranges\\\\\\\": \\\", \\\"{{$.inputs.parameters['reserved_ip_ranges']}}\\\"]}}}, \\\"\\\\\\\"enable_web_access\\\\\\\": false\\\", \\\"}\\\", \\\"}\\\"]}\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"exec-text-embedding-model-uploader\": {\n",
      "          \"container\": {\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.3.1\",\n",
      "            \"command\": [\n",
      "              \"sh\",\n",
      "              \"-ec\",\n",
      "              \"program_path=$(mktemp -d)\\n\\nprintf \\\"%s\\\" \\\"$0\\\" \\u003e \\\"$program_path/ephemeral_component.py\\\"\\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \\\"$program_path/ephemeral_component.py\\\"                         \\\"$@\\\"\\n\",\n",
      "              \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import *\\n\\ndef text_embedding_model_uploader(\\n    project: str,\\n    location: str,\\n    artifact_uri: dsl.Input[dsl.Artifact],\\n    model_reference_name: str,\\n    model_display_name: str,\\n    regional_endpoint: str,\\n    model_resource_name: dsl.OutputPath(str),\\n    gcp_resources: dsl.OutputPath(str),\\n    encryption_spec_key_name: str = '',\\n    upload_model: bool = True,\\n):\\n  \\\"\\\"\\\"Uploads tuned text embedding model.\\n\\n  Args:\\n      project: Name of the GCP project.\\n      location: Location for model upload and deployment.\\n      artifact_uri: KFP Artifact for adapter.\\n      model_reference_name: Large model reference name.\\n      model_display_name: Name of the model (shown in Model Registry).\\n      regional_endpoint: Regional API endpoint.\\n      encryption_spec_key_name: Customer-managed encryption key.\\n      upload_model: Whether to upload the model to the Model Registry. Default\\n        is ``True``. If ``False``, the model will not be uploaded and output\\n        artifacts will contain empty strings.\\n\\n  Returns:\\n      model_resource_name: Path to the created Model on Model Registry.\\n      gcp_resources: Serialized JSON of `gcp_resources`.\\n  \\\"\\\"\\\"\\n  import json\\n  import logging\\n  import os\\n  import sys\\n\\n  try:\\n    from google_cloud_pipeline_components.container.v1.gcp_launcher import lro_remote_runner\\n  except ImportError:\\n    from google_cloud_pipeline_components.google_cloud_pipeline_components.container.v1.gcp_launcher import lro_remote_runner\\n\\n  try:\\n    os.makedirs(os.path.dirname(model_resource_name), exist_ok=True)\\n\\n    if not upload_model:\\n      with open(model_resource_name, 'w') as fout:\\n        fout.write('')\\n      return\\n\\n    pipeline_labels_str = os.getenv('VERTEX_AI_PIPELINES_RUN_LABELS')\\n    labels = json.loads(pipeline_labels_str) if pipeline_labels_str else {}\\n    labels['google-vertex-llm-tuning-base-model-id'] = (\\n        model_reference_name.replace('@', '-')\\n    )\\n\\n    model_upload_payload = {\\n        'model': {\\n            'artifactUri': artifact_uri.uri,\\n            'containerSpec': {\\n                'imageUri': 'us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.2-11:latest'\\n            },\\n            'displayName': model_display_name,\\n            'generatedModelSource': {\\n                'model_garden_source': {\\n                    'public_model_name': 'tuned-text-embedding-model'\\n                }\\n            },\\n            'labels': labels,\\n        }\\n    }\\n    if encryption_spec_key_name:\\n      model_upload_payload['model']['encryption_spec'] = {\\n          'kms_key_name': encryption_spec_key_name\\n      }\\n\\n    upload_model_uri = (\\n        f'{regional_endpoint.rstrip(\\\"/\\\")}/'\\n        f'projects/{project}/locations/{location}/models:upload'\\n    )\\n\\n    remote_runner = lro_remote_runner.LroRemoteRunner(location)\\n    upload_model_lro = remote_runner.create_lro(\\n        upload_model_uri,\\n        json.dumps(model_upload_payload),\\n        gcp_resources,\\n    )\\n    upload_model_lro = remote_runner.poll_lro(lro=upload_model_lro)\\n    model_resource = upload_model_lro['response']['model']\\n    model_version_id = upload_model_lro['response'].get(\\n        'model_version_id'\\n    ) or upload_model_lro['response'].get('modelVersionId')\\n    if model_version_id:\\n      model_resource += f'@{model_version_id}'\\n\\n    with open(model_resource_name, 'w') as fout:\\n      fout.write(model_resource)\\n\\n  except Exception as e:  # pylint: disable=broad-exception-caught\\n    if isinstance(e, ValueError):\\n      raise\\n    logging.exception(str(e))\\n    sys.exit(13)\\n\\n\"\n",
      "            ],\n",
      "            \"args\": [\n",
      "              \"--executor_input\",\n",
      "              \"{{$}}\",\n",
      "              \"--function_to_execute\",\n",
      "              \"text_embedding_model_uploader\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"exec-text-embedding-trainer\": {\n",
      "          \"container\": {\n",
      "            \"image\": \"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.0.0b3\",\n",
      "            \"command\": [\n",
      "              \"python3\",\n",
      "              \"-u\",\n",
      "              \"-m\",\n",
      "              \"google_cloud_pipeline_components.container.v1.custom_job.launcher\"\n",
      "            ],\n",
      "            \"args\": [\n",
      "              \"--type\",\n",
      "              \"CustomJob\",\n",
      "              \"--project\",\n",
      "              \"{{$.inputs.parameters['project']}}\",\n",
      "              \"--location\",\n",
      "              \"{{$.inputs.parameters['location']}}\",\n",
      "              \"--gcp_resources\",\n",
      "              \"{{$.outputs.parameters['gcp_resources'].output_file}}\",\n",
      "              \"--payload\",\n",
      "              \"{\\\"Concat\\\": [\\\"{\\\", \\\"\\\\\\\"display_name\\\\\\\": \\\\\\\"Text_Embedding_Trainer_{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"encryption_spec_key_name\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"encryption_spec\\\\\\\": {\\\", \\\"\\\\\\\"kms_key_name\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['encryption_spec_key_name']}}\\\", \\\"\\\\\\\"\\\", \\\"},\\\"]}}}, \\\"\\\\\\\"job_spec\\\\\\\": {\\\", \\\"\\\\\\\"worker_pool_specs\\\\\\\": [\\\", \\\"{\\\", \\\"\\\\\\\"machine_spec\\\\\\\": {\\\", \\\"\\\\\\\"machine_type\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['machine_type']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"accelerator_type\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['accelerator_type']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"accelerator_count\\\\\\\": \\\", \\\"{{$.inputs.parameters['accelerator_count']}}\\\", \\\"},\\\", \\\"\\\\\\\"replica_count\\\\\\\": \\\", \\\"{{$.inputs.parameters['replica_count']}}\\\", \\\",\\\", \\\"\\\\\\\"disk_spec\\\\\\\": {\\\", \\\"\\\\\\\"boot_disk_type\\\\\\\": \\\\\\\"pd-ssd\\\\\\\",\\\", \\\"\\\\\\\"boot_disk_size_gb\\\\\\\": 100\\\", \\\"},\\\", \\\"\\\\\\\"container_spec\\\\\\\": {\\\", \\\"\\\\\\\"image_uri\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['image_uri']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"args\\\\\\\": [\\\", \\\"\\\\\\\"--queries_path=\\\", \\\"{{$.inputs.parameters['queries_path']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--corpus_path=\\\", \\\"{{$.inputs.parameters['corpus_path']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--train_label_path=\\\", \\\"{{$.inputs.parameters['train_label_path']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--run_evaluation_and_final_export=\\\", \\\"{{$.inputs.parameters['run_evaluation_and_final_export']}}\\\", \\\"\\\\\\\",\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"validation_label_path\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--validation_label_path=\\\", \\\"{{$.inputs.parameters['validation_label_path']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"test_label_path\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--test_label_path=\\\", \\\"{{$.inputs.parameters['test_label_path']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"base_model_version_id\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--base_model_version_id=\\\", \\\"{{$.inputs.parameters['base_model_version_id']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"task_type\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"--task_type=\\\", \\\"{{$.inputs.parameters['task_type']}}\\\", \\\"\\\\\\\",\\\"]}}}, \\\"\\\\\\\"--batch_size=\\\", \\\"{{$.inputs.parameters['batch_size']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--iterations=\\\", \\\"{{$.inputs.parameters['iterations']}}\\\", \\\"\\\\\\\",\\\", \\\"\\\\\\\"--executor_input={{$.json_escape[1]}}\\\\\\\"\\\", \\\"]\\\", \\\"}\\\", \\\"}\\\", \\\"],\\\", {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"service_account\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"service_account\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['service_account']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"network\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"network\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['network']}}\\\", \\\"\\\\\\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"reserved_ip_ranges\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"reserved_ip_ranges\\\\\\\": \\\", \\\"{{$.inputs.parameters['reserved_ip_ranges']}}\\\", \\\",\\\"]}}}, {\\\"IfPresent\\\": {\\\"InputName\\\": \\\"tensorboard\\\", \\\"Then\\\": {\\\"Concat\\\": [\\\"\\\\\\\"tensorboard\\\\\\\": \\\\\\\"\\\", \\\"{{$.inputs.parameters['tensorboard']}}\\\", \\\"\\\\\\\",\\\"]}}}, \\\"\\\\\\\"enable_web_access\\\\\\\": false\\\", \\\"}\\\", \\\"}\\\"]}\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"state\": \"PIPELINE_STATE_PENDING\",\n",
      "  \"labels\": {\n",
      "    \"vertex-ai-pipelines-run-billing-id\": \"9191545848155078656\"\n",
      "  },\n",
      "  \"runtimeConfig\": {\n",
      "    \"gcsOutputDirectory\": \"gs://ecomm-query-product-pairs\",\n",
      "    \"parameterValues\": {\n",
      "      \"project\": \"wortz-project-352116\",\n",
      "      \"base_model_version_id\": \"textembedding-gecko@003\",\n",
      "      \"task_type\": \"SEMANTIC_SIMILARITY\",\n",
      "      \"location\": \"us-central1\",\n",
      "      \"queries_path\": \"gs://ecomm-query-product-pairs/tuning_data/query.jsonl\",\n",
      "      \"corpus_path\": \"gs://ecomm-query-product-pairs/tuning_data/corpus.jsonl\",\n",
      "      \"train_label_path\": \"gs://ecomm-query-product-pairs/tuning_data/corpus-train.TSV\",\n",
      "      \"test_label_path\": \"gs://ecomm-query-product-pairs/tuning_data/corpus-test.TSV\",\n",
      "      \"batch_size\": \"100\",\n",
      "      \"iterations\": \"1000\"\n",
      "    }\n",
      "  },\n",
      "  \"serviceAccount\": \"679926387543-compute@developer.gserviceaccount.com\",\n",
      "  \"templateUri\": \"https://us-kfp.pkg.dev/ml-pipeline/llm-text-embedding/tune-text-embedding-model/v1.1.1\",\n",
      "  \"templateMetadata\": {\n",
      "    \"version\": \"sha256:56f4767de7007eb96a6177081df6b39fb48ad56fe76017453288b55ef2949fb5\"\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100 78570    0 77726  100   844   268k   2982 --:--:-- --:--:-- --:--:--  271k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "BUCKET='gs://ecomm-query-product-pairs'\n",
    "PROJECT_ID=wortz-project-352116\n",
    "BASE_MODEL_VERSION_ID='textembedding-gecko@003'\n",
    "TASK_TYPE=SEMANTIC_SIMILARITY\n",
    "PIPELINE_SCRATCH_PATH=${BUCKET}\n",
    "QUERIES_PATH=${BUCKET}/tuning_data/query.jsonl\n",
    "CORPUS_PATH=${BUCKET}/tuning_data/corpus.jsonl\n",
    "TRAIN_LABEL_PATH=${BUCKET}/tuning_data/corpus-train.TSV\n",
    "TEST_LABEL_PATH=${BUCKET}/tuning_data/corpus-test.TSV\n",
    "BATCH_SIZE=100\n",
    "ITERATIONS=1000\n",
    "\n",
    "\n",
    "curl -X POST  \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "\"https://us-central1-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/us-central1/pipelineJobs?pipelineJobId=tune-text-embedding-$(date +%Y%m%d%H%M%S)\" \\\n",
    "-d '{\n",
    "  \"displayName\": \"tune-text-embedding-model\",\n",
    "  \"runtimeConfig\": {\n",
    "    \"gcsOutputDirectory\": \"'${PIPELINE_SCRATCH_PATH}'\",\n",
    "    \"parameterValues\": {\n",
    "      \"project\":  \"'${PROJECT_ID}'\",\n",
    "      \"base_model_version_id\":  \"'${BASE_MODEL_VERSION_ID}'\",\n",
    "      \"task_type\": \"'${TASK_TYPE}'\",\n",
    "      \"location\": \"us-central1\",\n",
    "      \"queries_path\":  \"'${QUERIES_PATH}'\",\n",
    "      \"corpus_path\":  \"'${CORPUS_PATH}'\",\n",
    "      \"train_label_path\":  \"'${TRAIN_LABEL_PATH}'\",\n",
    "      \"test_label_path\":  \"'${TEST_LABEL_PATH}'\",\n",
    "      \"batch_size\":  \"'${BATCH_SIZE}'\",\n",
    "      \"iterations\":  \"'${ITERATIONS}'\"\n",
    "    }\n",
    "  },\n",
    "  \"templateUri\": \"https://us-kfp.pkg.dev/ml-pipeline/llm-text-embedding/tune-text-embedding-model/v1.1.1\"\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_fine_tuning_dataframe(raw_data: datasets.dataset_dict.DatasetDict, unique_queries: Dict, unique_products: Dict, split: str = 'train') -> Tuple[pd.Dataframe, pd.Dataframe]:\n",
    "#     ### https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-embeddings#generative-ai-tune-embedding-drest\n",
    "#     data_dict_corpus = {\"_id\": [], \"text\": []}\n",
    "#     data_dict_query = data_dict_corpus.copy()\n",
    "#     raw_data = raw_data[split]\n",
    "#     for row in raw_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dataframe(\n",
    "    raw_data: Dict,\n",
    "    user_prompt: str = USER_PROMPT,\n",
    "    product_prompt: str = PRODUCT_PROMPT,\n",
    "    limit: int = LIMIT,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function returns batch prediction data for embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    for i, row in enumerate(raw_data[\"train\"]):\n",
    "        if i == limit - 1:\n",
    "            break\n",
    "        elif i == 0:\n",
    "            query_prod_pairs = pd.DataFrame(\n",
    "                {\n",
    "                    \"content\": [f'{user_prompt}{row[\"query\"]}'],\n",
    "                    \"type\": [\"query\"],\n",
    "                    \"id\": [row[\"query_id\"]],\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            query_prod_pairs = pd.concat(\n",
    "                [\n",
    "                    query_prod_pairs,\n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                            \"content\": [f'{user_prompt}{row[\"query\"]}'],\n",
    "                            \"type\": [\"query\"],\n",
    "                            \"id\": [row[\"query_id\"]],\n",
    "                        }\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        query_prod_pairs = pd.concat(\n",
    "            [\n",
    "                query_prod_pairs,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"content\": [f'{product_prompt}{row[\"product_title\"]}'],\n",
    "                        \"type\": [\"product_title\"],\n",
    "                        \"id\": [row[\"product_id\"]],\n",
    "                    }\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    return query_prod_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod_pairs = get_input_dataframe(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod_pairs = query_prod_pairs.reset_index()\n",
    "query_prod_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get unique product ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch prediction\n",
    "\n",
    "https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/batch-prediction-genai-embeddings#request_a_batch_response\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil mb $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"batch_prediction_inputs.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(query_prod_pairs[[\"content\"]].to_json(lines=True, orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp $output_file $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "now_string_tag = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(\"Tag for this run: \", now_string_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "textembedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko\")\n",
    "batch_prediction_job = textembedding_model.batch_predict(\n",
    "    dataset=[f\"{BUCKET}/{output_file}\"],\n",
    "    destination_uri_prefix=f\"{BUCKET}/batch-predict-{now_string_tag}\",\n",
    ")\n",
    "print(batch_prediction_job.display_name)\n",
    "print(batch_prediction_job.resource_name)\n",
    "print(batch_prediction_job.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When complete you should see something like this\n",
    "\n",
    "<img src='../img/bp-job.png' width=600px />\n",
    "\n",
    "<img src='../img/output-data.png' width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the embeddings with Tensorboard\n",
    "\n",
    "Following this guide https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_output_gcs_folder = batch_prediction_job.output_info.gcs_output_directory\n",
    "\n",
    "! gsutil cp $bp_output_gcs_folder/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_json(path_or_buf=\"000000000000.jsonl\", lines=True)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df: pd.DataFrame) -> List[List[float]]:\n",
    "    embedding_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        single_emb = row[\"predictions\"][0][\"embeddings\"][\"values\"]\n",
    "        embedding_list.append(single_emb)\n",
    "    return embedding_list\n",
    "\n",
    "\n",
    "embedding_list = get_predictions(predictions)\n",
    "len(embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files.\n",
    "log_dir = \"logs/ecomm-example/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, \"metadata.tsv\"), \"w\") as f:\n",
    "    # header for columns\n",
    "    f.write(\"data_type\\tdata\\n\")\n",
    "    for instance in predictions.instance:\n",
    "        data_type = instance[\"content\"].split(\": \")[0]\n",
    "        # data_type = data_type\n",
    "        data = \"\".join(instance[\"content\"].split(\": \")[1:])\n",
    "        f.write(f\"{data_type}\\t{data}\\n\")\n",
    "\n",
    "\n",
    "# Save the weights we want to analyze as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, here\n",
    "# we will remove this value.\n",
    "weights = tf.Variable(embedding_list)\n",
    "# Create a checkpoint from embedding, the filename and key are the\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = \"metadata.tsv\"\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run tensorboard against on log data we just saved.\n",
    "%tensorboard --logdir logs/ecomm-example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above will run until you stop it\n",
    "\n",
    "You should be able to investigate the embedding space via PCA. Note the total variance captured to understand how much information is captured from the 3d view\n",
    "\n",
    "<img src=\"../img/tensorboard.png\" width=600px />\n",
    "\n",
    "\n",
    "#### Also a great way to understand performance is to select a point of interest and top k neighbors appear\n",
    "\n",
    "Below, we see natural hair dye query and it's associated nearest product description in the embedding space:\n",
    "\n",
    "\n",
    "<img src=\"../img/knn-analysis.png\" width=900px />\n",
    "\n",
    "\n",
    "#### Lastly, you can analyze and color by data type to get a feel for how well the queries relate to the products\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../img/analysis-by-type.png\" width=900px />\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorboard-four-tensorboard-four",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "tensorboard-four",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

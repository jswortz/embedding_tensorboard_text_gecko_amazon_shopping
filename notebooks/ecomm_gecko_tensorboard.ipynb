{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigframes.pandas as bpd\n",
    "\n",
    "PROJECT_ID = 'wortz-project-352116'\n",
    "DATASET = 'ecomm-embedding'\n",
    "bpd.options.bigquery.project = PROJECT_ID\n",
    "BUCKET = 'gs://ecomm-query-product-pairs'\n",
    "USER_PROMPT = 'User query: '\n",
    "PRODUCT_PROMPT = 'Product title: '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_data = load_dataset(\"tasksource/esci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "LIMIT = 3000\n",
    "\n",
    "\n",
    "def get_input_dataframe(\n",
    "    raw_data: Dict,\n",
    "    user_prompt: str = USER_PROMPT,\n",
    "    product_prompt: str = PRODUCT_PROMPT,\n",
    "    limit: int = LIMIT,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    for i, row in enumerate(raw_data[\"train\"]):\n",
    "        if i == limit - 1:\n",
    "            break\n",
    "        elif i == 0:\n",
    "            query_prod_pairs = pd.DataFrame(\n",
    "                {\"content\": [f'{user_prompt}{row[\"query\"]}'], \"type\": [\"query\"]}\n",
    "            )\n",
    "        else:\n",
    "            query_prod_pairs = pd.concat(\n",
    "                [\n",
    "                    query_prod_pairs,\n",
    "                    pd.DataFrame(\n",
    "                        {\"content\": [f'{user_prompt}{row[\"query\"]}'], \"type\": [\"query\"]}\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        query_prod_pairs = pd.concat(\n",
    "            [\n",
    "                query_prod_pairs,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"content\": [f'{product_prompt}{row[\"product_title\"]}'],\n",
    "                        \"type\": [\"product_title\"],\n",
    "                    }\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    return query_prod_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod_pairs = get_input_dataframe(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>User query:  revent 80 cfm</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Product title: Panasonic FV-20VQ3 WhisperCeili...</td>\n",
       "      <td>product_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>User query: bathroom fan without light</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Product title: Panasonic FV-20VQ3 WhisperCeili...</td>\n",
       "      <td>product_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>User query:  revent 80 cfm</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            content           type\n",
       "0      0                         User query:  revent 80 cfm          query\n",
       "1      0  Product title: Panasonic FV-20VQ3 WhisperCeili...  product_title\n",
       "2      0             User query: bathroom fan without light          query\n",
       "3      0  Product title: Panasonic FV-20VQ3 WhisperCeili...  product_title\n",
       "4      0                         User query:  revent 80 cfm          query"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_prod_pairs = query_prod_pairs.reset_index()\n",
    "query_prod_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch prediction\n",
    "\n",
    "https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/batch-prediction-genai-embeddings#request_a_batch_response\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://ecomm-query-product-pairs/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'ecomm-query-product-pairs' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'batch_prediction_inputs.jsonl'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(query_prod_pairs[['content']].to_json(lines=True, orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://batch_prediction_inputs.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][585.1 KiB/585.1 KiB]                                                \n",
      "Operation completed over 1 objects/585.1 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp $output_file $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag for this run:  2024-03-19-03-12-42\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "now_string_tag = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(\"Tag for this run: \", now_string_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob created. Resource name: projects/679926387543/locations/us-central1/batchPredictionJobs/8242719746345140224\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/679926387543/locations/us-central1/batchPredictionJobs/8242719746345140224')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/8242719746345140224?project=679926387543\n",
      "BatchPredictionJob projects/679926387543/locations/us-central1/batchPredictionJobs/8242719746345140224 current state:\n",
      "JobState.JOB_STATE_QUEUED\n",
      "BatchPredictionJob projects/679926387543/locations/us-central1/batchPredictionJobs/8242719746345140224 current state:\n",
      "JobState.JOB_STATE_QUEUED\n",
      "BatchPredictionJob projects/679926387543/locations/us-central1/batchPredictionJobs/8242719746345140224 current state:\n",
      "JobState.JOB_STATE_QUEUED\n",
      "BatchPredictionJob projects/679926387543/locations/us-central1/batchPredictionJobs/8242719746345140224 current state:\n",
      "JobState.JOB_STATE_QUEUED\n",
      "BatchPredictionJob projects/679926387543/locations/us-central1/batchPredictionJobs/8242719746345140224 current state:\n",
      "JobState.JOB_STATE_QUEUED\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "textembedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko\")\n",
    "batch_prediction_job = textembedding_model.batch_predict(\n",
    "  dataset=[f\"{BUCKET}/{output_file}\"],\n",
    "  destination_uri_prefix=f\"{BUCKET}/batch-predict-{now_string_tag}\",\n",
    ")\n",
    "print(batch_prediction_job.display_name)\n",
    "print(batch_prediction_job.resource_name)\n",
    "print(batch_prediction_job.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When complete you should see something like this\n",
    "\n",
    "<img src='../img/bp-job.png' width=600px />\n",
    "\n",
    "<img src='../img/output-data.png' width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the embeddings with Tensorboard\n",
    "\n",
    "Following this guide https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedding_env_march",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

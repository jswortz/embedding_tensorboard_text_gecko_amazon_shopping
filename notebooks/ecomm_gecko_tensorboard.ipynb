{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting batch prediction EDA with Tensor Board and Text Gecko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, List\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "LIMIT = 3000\n",
    "PROJECT_ID = 'wortz-project-352116'\n",
    "DATASET = 'ecomm-embedding'\n",
    "BUCKET = 'gs://ecomm-query-product-pairs'\n",
    "USER_PROMPT = 'User query: '\n",
    "PRODUCT_PROMPT = 'Product title: '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_dataset(\"tasksource/esci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dataframe(\n",
    "    raw_data: Dict,\n",
    "    user_prompt: str = USER_PROMPT,\n",
    "    product_prompt: str = PRODUCT_PROMPT,\n",
    "    limit: int = LIMIT,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function returns batch prediction data for embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    for i, row in enumerate(raw_data[\"train\"]):\n",
    "        if i == limit - 1:\n",
    "            break\n",
    "        elif i == 0:\n",
    "            query_prod_pairs = pd.DataFrame(\n",
    "                {\"content\": [f'{user_prompt}{row[\"query\"]}'], \"type\": [\"query\"]}\n",
    "            )\n",
    "        else:\n",
    "            query_prod_pairs = pd.concat(\n",
    "                [\n",
    "                    query_prod_pairs,\n",
    "                    pd.DataFrame(\n",
    "                        {\"content\": [f'{user_prompt}{row[\"query\"]}'], \"type\": [\"query\"]}\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        query_prod_pairs = pd.concat(\n",
    "            [\n",
    "                query_prod_pairs,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"content\": [f'{product_prompt}{row[\"product_title\"]}'],\n",
    "                        \"type\": [\"product_title\"],\n",
    "                    }\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    return query_prod_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod_pairs = get_input_dataframe(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod_pairs = query_prod_pairs.reset_index()\n",
    "query_prod_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch prediction\n",
    "\n",
    "https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/batch-prediction-genai-embeddings#request_a_batch_response\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil mb $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'batch_prediction_inputs.jsonl'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(query_prod_pairs[['content']].to_json(lines=True, orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp $output_file $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "now_string_tag = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(\"Tag for this run: \", now_string_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "textembedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko\")\n",
    "batch_prediction_job = textembedding_model.batch_predict(\n",
    "    dataset=[f\"{BUCKET}/{output_file}\"],\n",
    "    destination_uri_prefix=f\"{BUCKET}/batch-predict-{now_string_tag}\",\n",
    ")\n",
    "print(batch_prediction_job.display_name)\n",
    "print(batch_prediction_job.resource_name)\n",
    "print(batch_prediction_job.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When complete you should see something like this\n",
    "\n",
    "<img src='../img/bp-job.png' width=600px />\n",
    "\n",
    "<img src='../img/output-data.png' width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the embeddings with Tensorboard\n",
    "\n",
    "Following this guide https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_output_gcs_folder = batch_prediction_job.output_info.gcs_output_directory\n",
    "\n",
    "! gsutil cp $bp_output_gcs_folder/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_json(path_or_buf='000000000000.jsonl', lines=True)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df: pd.DataFrame) -> List[List[float]]:\n",
    "    embedding_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        single_emb = row['predictions'][0]['embeddings']['values']\n",
    "        embedding_list.append(single_emb)\n",
    "    return embedding_list\n",
    "\n",
    "embedding_list = get_predictions(predictions)\n",
    "len(embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files.\n",
    "log_dir = \"logs/ecomm-example/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, \"metadata.tsv\"), \"w\") as f:\n",
    "    for instance in predictions.instance:\n",
    "        data_type = instance['content'].split(': ')[0]\n",
    "        # data_type = data_type\n",
    "        data = ''.join(instance['content'].split(': ')[1:])\n",
    "        f.write(f\"{data_type}    {data}\\n\")\n",
    "\n",
    "\n",
    "# Save the weights we want to analyze as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, here\n",
    "# we will remove this value.\n",
    "weights = tf.Variable(embedding_list)\n",
    "# Create a checkpoint from embedding, the filename and key are the\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = \"metadata.tsv\"\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run tensorboard against on log data we just saved.\n",
    "%tensorboard --logdir logs/ecomm-example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above will run until you stop it\n",
    "\n",
    "You should be able to investigate the embedding space via PCA. Note the total variance captured to understand how complete the veiw investigate\n",
    "\n",
    "<img src=\"../img/tensorboard.png\" width=600px />\n",
    "\n",
    "\n",
    "#### Also a great way to understand performance is to select a point of interest and top k neighbors appear\n",
    "\n",
    "Below, we see natural hair dye query and it's associated nearest product description in the embedding space:\n",
    "\n",
    "\n",
    "<img src=\"../img/knn-analysis.png\" width=900px />\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorboard-four-tensorboard-four",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "tensorboard-four (Local)",
   "language": "python",
   "name": "conda-env-tensorboard-four-tensorboard-four"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
